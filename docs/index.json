[{"authors":["admin"],"categories":null,"content":"Experienced data analyst with a thorough understanding of complex statistical methods, experience with a variety of statistical tools, and knowledge in finance and financial analyses. I am a leader and dependable colleague with a unique array of past experiences that bring a new perspective to the workplace. I work well independently, but thrive in team-based environments that are fast paced and dynamic.\n","date":1554595200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1567641600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/colin-benusa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/colin-benusa/","section":"authors","summary":"Experienced data analyst with a thorough understanding of complex statistical methods, experience with a variety of statistical tools, and knowledge in finance and financial analyses. I am a leader and dependable colleague with a unique array of past experiences that bring a new perspective to the workplace.","tags":null,"title":"Colin Benusa","type":"authors"},{"authors":["admin"],"categories":null,"content":"Experienced data analyst with a thorough understanding of complex statistical methods, experience with a variety of statistical tools, and knowledge in finance and financial analyses. I am a leader and dependable colleague with a unique array of past experiences that bring a new perspective to the workplace. I work well independently, but thrive in team-based environments that are fast paced and dynamic.\n","date":1461110400,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1555459200,"objectID":"da99cb196019cc5857b9b3e950397ca9","permalink":"/author/colin-benusa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/colin-benusa/","section":"authors","summary":"Experienced data analyst with a thorough understanding of complex statistical methods, experience with a variety of statistical tools, and knowledge in finance and financial analyses. I am a leader and dependable colleague with a unique array of past experiences that bring a new perspective to the workplace.","tags":null,"title":"Colin Benusa","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":[],"categories":[],"content":" Reading in Data From FRED #install.packages(\u0026quot;modelr\u0026quot;) #install.packages(\u0026quot;FinCal\u0026quot;) #install.packages(\u0026quot;dplyr\u0026quot;) #install.packages(\u0026quot;FinancialMath\u0026quot;) #install.packages(\u0026quot;devtools\u0026quot;) #install.packages(\u0026quot;tidyverse\u0026quot;) #install.packages(\u0026quot;dplyr\u0026quot;) #install.packages(\u0026quot;ggpubr\u0026quot;) #install.packages(\u0026quot;epitools\u0026quot;) #install.packages(\u0026quot;data.table\u0026quot;) #install.packages(\u0026quot;usmap\u0026quot;) #install.packages(\u0026quot;maps\u0026quot;) #install.packages(\u0026quot;cowplot\u0026quot;) #install.packages(\u0026quot;ztable\u0026quot;) library(\u0026quot;modelr\u0026quot;) library(\u0026quot;FinCal\u0026quot;) library(\u0026quot;dplyr\u0026quot;) ## ## Attaching package: \u0026#39;dplyr\u0026#39; ## The following objects are masked from \u0026#39;package:stats\u0026#39;: ## ## filter, lag ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## intersect, setdiff, setequal, union library(\u0026quot;FinancialMath\u0026quot;) library(\u0026quot;ggplot2\u0026quot;) library(\u0026quot;quantmod\u0026quot;) ## Loading required package: xts ## Warning: package \u0026#39;xts\u0026#39; was built under R version 3.5.2 ## Loading required package: zoo ## ## Attaching package: \u0026#39;zoo\u0026#39; ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## as.Date, as.Date.numeric ## ## Attaching package: \u0026#39;xts\u0026#39; ## The following objects are masked from \u0026#39;package:dplyr\u0026#39;: ## ## first, last ## Loading required package: TTR ## Warning: package \u0026#39;TTR\u0026#39; was built under R version 3.5.2 ## Version 0.4-0 included new data defaults. See ?getSymbols. ## ## Attaching package: \u0026#39;quantmod\u0026#39; ## The following object is masked from \u0026#39;package:FinCal\u0026#39;: ## ## lineChart library(\u0026quot;epitools\u0026quot;) ## Warning: package \u0026#39;epitools\u0026#39; was built under R version 3.5.2 library(\u0026quot;data.table\u0026quot;) ## Warning: package \u0026#39;data.table\u0026#39; was built under R version 3.5.2 ## ## Attaching package: \u0026#39;data.table\u0026#39; ## The following objects are masked from \u0026#39;package:xts\u0026#39;: ## ## first, last ## The following objects are masked from \u0026#39;package:dplyr\u0026#39;: ## ## between, first, last library(\u0026quot;usmap\u0026quot;) ## Warning: package \u0026#39;usmap\u0026#39; was built under R version 3.5.2 library(\u0026quot;maps\u0026quot;) library(\u0026quot;cowplot\u0026quot;) ## Warning: package \u0026#39;cowplot\u0026#39; was built under R version 3.5.2 ## ## ******************************************************** ## Note: As of version 1.0.0, cowplot does not change the ## default ggplot2 theme anymore. To recover the previous ## behavior, execute: ## theme_set(theme_cowplot()) ## ******************************************************** library(\u0026quot;ztable\u0026quot;) ## Welcome to package ztable ver 0.2.0  Connecting to FRED through an R package downloaded from GitHub  US GDP from Jan 1st, 1990 to today #See https://fred.stlouisfed.org/docs/api/fred/ for FRED Data information #See https://fred.stlouisfed.org/tags/series for series IDs fredr(series_id = \u0026quot;UNRATE\u0026quot;, observation_start = as.Date(\u0026quot;1990-01-01\u0026quot;)) ## # A tibble: 367 x 3 ## date series_id value ## \u0026lt;date\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1990-01-01 UNRATE 5.4 ## 2 1990-02-01 UNRATE 5.3 ## 3 1990-03-01 UNRATE 5.2 ## 4 1990-04-01 UNRATE 5.4 ## 5 1990-05-01 UNRATE 5.4 ## 6 1990-06-01 UNRATE 5.2 ## 7 1990-07-01 UNRATE 5.5 ## 8 1990-08-01 UNRATE 5.7 ## 9 1990-09-01 UNRATE 5.9 ## 10 1990-10-01 UNRATE 5.9 ## # … with 357 more rows #US GDP from Jan 1st 1990 to now GDP \u0026lt;- fredr(series_id = \u0026quot;GDP\u0026quot;, observation_start = as.Date(\u0026quot;1990-01-01\u0026quot;)) GDP %\u0026gt;% ggplot(aes(x = date, y = value)) + geom_line() + ggtitle(\u0026quot;GDP for US in Billions of Dollars\u0026quot;) + labs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;Billions of Dollars\u0026quot;) [Us GDP has steadily increased since 1990 with slight deviations from norm in 2009 and most recently 2020. 2009 deviation explained by 2008 financial crisis, and 2020 deviation explained by the COVID pandemic.]\n Percentage Change in Richmond, Virginia Poverty Rate since January 7,1990 #Change in Richmond, Virginia Poverty Rate since January 7,1990 RVA_POV \u0026lt;- fredr(series_id = \u0026quot;S1701ACS051760\u0026quot;, observation_start = as.Date(\u0026quot;2013-01-01\u0026quot;), frequency = \u0026quot;a\u0026quot;) RVA_POV %\u0026gt;% ggplot(aes(x = date, y = value)) + geom_line() + ggtitle(\u0026quot;Poverty Rate for Richmond VA\u0026quot;) + labs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;% of Population\u0026quot;) [Poverty Rate in Richmond, Virginia has decreased since 2013 from 25.6% to 24.5%. With an economy that improved substantially during this time period, this observation doesn’t seem difficult to imagine]\n#Home ownership rate for Virginia VA_Home \u0026lt;- fredr(series_id = \u0026quot;VAHOWN\u0026quot;, observation_start = as.Date(\u0026quot;1984-01-01\u0026quot;), frequency = \u0026quot;a\u0026quot;) VA_Home %\u0026gt;% ggplot(aes(x = date, y = value)) + geom_line() + ggtitle(\u0026quot;Home Ownership in VA\u0026quot;) + labs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;% in Population\u0026quot;) [Home Ownership in Virginia appears to have peaks in 1989, 1994, 2001, 2003, 2007, 2013, 2017 and 2019. From this visualization you can clearly see the the housing bubble in the early 2000s that led to the 2008 financial crisis. Home ownership appears to have a slight decline since 2007.]\n Correlation Analysis of TIPS Interest Rates and NYSE Stock Prices #Daily Interest Rates for 10 Year Treasury Inflation Indexed Securities T_INT_RATES \u0026lt;- fredr(series_id = \u0026quot;DFII10\u0026quot;, observation_start = as.Date(\u0026quot;2003-01-02\u0026quot;), frequency = \u0026quot;d\u0026quot;) #Daily Stock Data is downloaded using quantmod DJI \u0026lt;- getSymbols(\u0026quot;DIA\u0026quot;, src = \u0026quot;yahoo\u0026quot;, from = \u0026#39;2003-01-02\u0026#39;, to = \u0026quot;2020-07-31\u0026quot;, auto.assign = TRUE) ## \u0026#39;getSymbols\u0026#39; currently uses auto.assign=TRUE by default, but will ## use auto.assign=FALSE in 0.5-0. You will still be able to use ## \u0026#39;loadSymbols\u0026#39; to automatically load data. getOption(\u0026quot;getSymbols.env\u0026quot;) ## and getOption(\u0026quot;getSymbols.auto.assign\u0026quot;) will still be checked for ## alternate defaults. ## ## This message is shown once per session and may be disabled by setting ## options(\u0026quot;getSymbols.warning4.0\u0026quot;=FALSE). See ?getSymbols for details. DIA_Daily_Return \u0026lt;- dailyReturn(DIA) #Daily Stock Prices are Plotted DIA_Daily_Return %\u0026gt;% ggplot(aes(x = index(DIA_Daily_Return), y = daily.returns)) + geom_line(size=0.5, color=\u0026quot;steel blue\u0026quot;) + ggtitle(\u0026quot;Daily Return for Dow Jones ETF since 2003\u0026quot;) + scale_x_date(date_breaks = \u0026quot;years\u0026quot;, date_labels = \u0026quot;%Y\u0026quot;) + labs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;Adjusted Price\u0026quot;) #Left Join by Date DIA_Daily_Return \u0026lt;- data.frame(DIA_Daily_Return) DIA_Daily_Return$date \u0026lt;- as.Date(rownames(DIA_Daily_Return)) T_INT_RATES$TIPS_Rate \u0026lt;- T_INT_RATES$value Int_Rate_Stock_Data \u0026lt;- merge(x = DIA_Daily_Return, y = T_INT_RATES, by = \u0026quot;date\u0026quot;, all.x = TRUE) head(Int_Rate_Stock_Data) ## date daily.returns series_id value TIPS_Rate ## 1 2003-01-02 0.0241235645 DFII10 2.43 2.43 ## 2 2003-01-03 0.0020886633 DFII10 2.43 2.43 ## 3 2003-01-06 0.0151690248 DFII10 2.46 2.46 ## 4 2003-01-07 0.0005703548 DFII10 2.42 2.42 ## 5 2003-01-08 -0.0176698926 DFII10 2.29 2.29 ## 6 2003-01-09 0.0186840088 DFII10 2.41 2.41 cor.test(Int_Rate_Stock_Data$daily.returns, Int_Rate_Stock_Data$TIPS_Rate) ## ## Pearson\u0026#39;s product-moment correlation ## ## data: Int_Rate_Stock_Data$daily.returns and Int_Rate_Stock_Data$TIPS_Rate ## t = -0.59466, df = 4391, p-value = 0.5521 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.03853599 0.02060440 ## sample estimates: ## cor ## -0.008973643 [Similarly, this analysis was done to try to determine if there was a strong correlation between the Dow Jones and Interest Rates for 10 Year Treasury Inflation Indexed Securities. The thought behind this was increased TIP rates signaled an improving economy thus causing an increase in the price of the Dow Jones Index and in this case an ETF. With a P value above the .05 threshold there is not enough evidence to suggest a relationship exists.]\n Correlation Analysis of TIPS Interest Rates and GDP #Daily Interest Rates for S\u0026amp;P/Case-Shiller U.S. National Home Price Index HPI \u0026lt;- fredr(series_id = \u0026quot;CSUSHPINSA\u0026quot;, observation_start = as.Date(\u0026quot;2003-01-02\u0026quot;), frequency = \u0026quot;m\u0026quot;) #Daily Stock Data is downloaded using quantmod DJI \u0026lt;- getSymbols(\u0026quot;DIA\u0026quot;, src = \u0026quot;yahoo\u0026quot;, from = \u0026#39;2003-01-02\u0026#39;, to = \u0026quot;2020-05-31\u0026quot;, auto.assign = TRUE) DIA_Monthly_Return \u0026lt;- monthlyReturn(DIA) #Left Join by Date DIA_Monthly_Return \u0026lt;- data.frame(DIA_Monthly_Return) DIA_Monthly_Return$date \u0026lt;- seq(as.Date(\u0026quot;2003/1/1\u0026quot;), as.Date(\u0026quot;2020/5/31\u0026quot;), by = \u0026quot;month\u0026quot;) HPI$index \u0026lt;- HPI$value HPI_Stock_Data \u0026lt;- merge(x = DIA_Monthly_Return, y = HPI, by = \u0026quot;date\u0026quot;, all.x = TRUE) head(HPI_Stock_Data) ## date monthly.returns series_id value index ## 1 2003-01-01 -0.039334592 CSUSHPINSA 127.652 127.652 ## 2 2003-02-01 -0.018926250 CSUSHPINSA 128.327 128.327 ## 3 2003-03-01 0.006430488 CSUSHPINSA 129.310 129.310 ## 4 2003-04-01 0.063142082 CSUSHPINSA 130.490 130.490 ## 5 2003-05-01 0.046900718 CSUSHPINSA 131.841 131.841 ## 6 2003-06-01 0.012044215 CSUSHPINSA 133.226 133.226 cor.test(HPI_Stock_Data$monthly.returns, HPI_Stock_Data$index) ## ## Pearson\u0026#39;s product-moment correlation ## ## data: HPI_Stock_Data$monthly.returns and HPI_Stock_Data$index ## t = -0.44315, df = 207, p-value = 0.6581 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.1658081 0.1053686 ## sample estimates: ## cor ## -0.03078631 [Similarly to the two analyses above, this analysis is done to determine if there was a relationship between the DJI and the S\u0026amp;P/Case-Schiller Housing Price Index. The thought behind this was an increased housing price index signaled an improving economy, causing an increase in the price of the Dow Jones Index and in this case an ETF. With a P value above the .05 threshold there is not enough evidence to suggest a relationship exists.]\n Total Gross Domestic Product Map by State #https://fred.stlouisfed.org/release?rid=140 #Created list of FRED variables. Values were divided into x and y groups because for some reason R would not run all of the variables in one group x \u0026lt;- list(\u0026quot;CARGSP\u0026quot;,\u0026quot;TXNGSP\u0026quot;, \u0026quot;NYNGSP\u0026quot;,\u0026quot;FLNGSP\u0026quot;,\u0026quot;OHNGSP\u0026quot;, \u0026quot;WANGSP\u0026quot;,\u0026quot;CONGSP\u0026quot;,\u0026quot;MINGSP\u0026quot;,\u0026quot;MANGSP\u0026quot;,\u0026quot;AZNGSP\u0026quot;,\u0026quot;HINGSP\u0026quot;,\u0026quot;PANGSP\u0026quot;, \u0026quot;NJNGSP\u0026quot;,\u0026quot;ILNGSP\u0026quot;,\u0026quot;NCNGSP\u0026quot;,\u0026quot;ALNGSP\u0026quot;,\u0026quot;MONGSP\u0026quot;,\u0026quot;LANGSP\u0026quot;,\u0026quot;WINGSP\u0026quot;,\u0026quot;MNNGSP\u0026quot;,\u0026quot;ORNGSP\u0026quot;,\u0026quot;MSNGSP\u0026quot;,\u0026quot;SCNGSP\u0026quot;,\u0026quot;CTNGSP\u0026quot;,\u0026quot;INNGSP\u0026quot;,\u0026quot;TNNGSP\u0026quot;,\u0026quot;KYNGSP\u0026quot;,\u0026quot;AKNGSP\u0026quot;,\u0026quot;DCNGSP\u0026quot;,\u0026quot;GANGSP\u0026quot;,\u0026quot;VANGSP\u0026quot;,\u0026quot;UTNGSP\u0026quot;,\u0026quot;IANGSP\u0026quot;,\u0026quot;NMNGSP\u0026quot;,\u0026quot;NDNGSP\u0026quot;,\u0026quot;WVNGSP\u0026quot;,\u0026quot;WYNGSP\u0026quot;,\u0026quot;MDNGSP\u0026quot;,\u0026quot;NENGSP\u0026quot;,\u0026quot;MENGSP\u0026quot;,\u0026quot;IDNGSP\u0026quot;,\u0026quot;NVNGSP\u0026quot;,\u0026quot;MTNGSP\u0026quot;,\u0026quot;KSNGSP\u0026quot;,\u0026quot;RINGSP\u0026quot;,\u0026quot;OKNGSP\u0026quot;,\u0026quot;VTNGSP\u0026quot;,\u0026quot;SDNGSP\u0026quot;,\u0026quot;ARNGSP\u0026quot;,\u0026quot;NHNGSP\u0026quot;,\u0026quot;DENGSP\u0026quot;) z \u0026lt;- list(\u0026quot;California\u0026quot;, \u0026quot;Texas\u0026quot;, \u0026quot;New York\u0026quot;,\u0026quot;Florida\u0026quot;,\u0026quot;Ohio\u0026quot;, \u0026quot;Washington\u0026quot;, \u0026quot;Colorado\u0026quot;,\u0026quot;Michigan\u0026quot;, \u0026quot;Massachusetts\u0026quot;,\u0026quot;Arizona\u0026quot;,\u0026quot;Hawaii\u0026quot;,\u0026quot;Pennsylvania\u0026quot;,\u0026quot;New Jersey\u0026quot;,\u0026quot;Illinois\u0026quot;,\u0026quot;North Carolina\u0026quot;,\u0026quot;Alabama\u0026quot;,\u0026quot;Missouri\u0026quot;,\u0026quot;Louisiana\u0026quot;,\u0026quot;Wisconsin\u0026quot;,\u0026quot;Minnesota\u0026quot;,\u0026quot;Oregon\u0026quot;,\u0026quot;Mississippi\u0026quot;,\u0026quot;South Carolina\u0026quot;,\u0026quot;Connecticut\u0026quot;,\u0026quot;Indiana\u0026quot;,\u0026quot;Tennessee\u0026quot;,\u0026quot;Kentucky\u0026quot;,\u0026quot;Alaska\u0026quot;, \u0026quot;District of Columbia\u0026quot;,\u0026quot;Georgia\u0026quot;,\u0026quot;Virginia\u0026quot;,\u0026quot;Utah\u0026quot;,\u0026quot;Iowa\u0026quot;,\u0026quot;New Mexico\u0026quot;,\u0026quot;North Dakota\u0026quot;,\u0026quot;West Virginia\u0026quot;,\u0026quot;Wyoming\u0026quot;,\u0026quot;Maryland\u0026quot;,\u0026quot;Nebraska\u0026quot;,\u0026quot;Maine\u0026quot;,\u0026quot;Idaho\u0026quot;,\u0026quot;Nevada\u0026quot;,\u0026quot;Montana\u0026quot;,\u0026quot;Kansas\u0026quot;,\u0026quot;Rhode Island\u0026quot;,\u0026quot;Oklahoma\u0026quot;,\u0026quot;Vermont\u0026quot;,\u0026quot;South Dakota\u0026quot;,\u0026quot;Arkansas\u0026quot;,\u0026quot;New Hampshire\u0026quot;,\u0026quot;Delaware\u0026quot;) #Loop Designed to run this function and name datasets by the FRED variable. for (p in x){ name \u0026lt;- fredr(series_id = p, observation_start = as.Date(\u0026quot;2003-01-02\u0026quot;), frequency = \u0026quot;a\u0026quot;) assign(p, name) } #Using the rbind function to combine all rows together for a full dataset with all states and years in one table GDP_ALL \u0026lt;- rbind(CARGSP$value,TXNGSP$value, NYNGSP$value,FLNGSP$value,OHNGSP$value, WANGSP$value,CONGSP$value,MINGSP$value,MANGSP$value,AZNGSP$value,HINGSP$value,PANGSP$value, NJNGSP$value,ILNGSP$value,NCNGSP$value,ALNGSP$value,MONGSP$value,LANGSP$value,WINGSP$value, MNNGSP$value,ORNGSP$value,MSNGSP$value,SCNGSP$value,CTNGSP$value,INNGSP$value,TNNGSP$value,KYNGSP$value,AKNGSP$value,DCNGSP$value,GANGSP$value,VANGSP$value,UTNGSP$value,IANGSP$value,NMNGSP$value,NDNGSP$value,WVNGSP$value,WYNGSP$value,MDNGSP$value,NENGSP$value,MENGSP$value,IDNGSP$value,NVNGSP$value,MTNGSP$value,KSNGSP$value,RINGSP$value,OKNGSP$value,VTNGSP$value,SDNGSP$value,ARNGSP$value,NHNGSP$value,DENGSP$value) value = c(\u0026quot;California\u0026quot;, \u0026quot;Texas\u0026quot;, \u0026quot;New York\u0026quot;,\u0026quot;Florida\u0026quot;,\u0026quot;Ohio\u0026quot;, \u0026quot;Washington\u0026quot;, \u0026quot;Colorado\u0026quot;,\u0026quot;Michigan\u0026quot;, \u0026quot;Massachusetts\u0026quot;,\u0026quot;Arizona\u0026quot;,\u0026quot;Hawaii\u0026quot;,\u0026quot;Pennsylvania\u0026quot;,\u0026quot;New Jersey\u0026quot;,\u0026quot;Illinois\u0026quot;,\u0026quot;North Carolina\u0026quot;,\u0026quot;Alabama\u0026quot;,\u0026quot;Missouri\u0026quot;,\u0026quot;Louisiana\u0026quot;,\u0026quot;Wisconsin\u0026quot;,\u0026quot;Minnesota\u0026quot;,\u0026quot;Oregon\u0026quot;,\u0026quot;Mississippi\u0026quot;,\u0026quot;South Carolina\u0026quot;,\u0026quot;Connecticut\u0026quot;,\u0026quot;Indiana\u0026quot;,\u0026quot;Tennessee\u0026quot;,\u0026quot;Kentucky\u0026quot;,\u0026quot;Alaska\u0026quot;, \u0026quot;District of Columbia\u0026quot;,\u0026quot;Georgia\u0026quot;,\u0026quot;Virginia\u0026quot;,\u0026quot;Utah\u0026quot;,\u0026quot;Iowa\u0026quot;,\u0026quot;New Mexico\u0026quot;,\u0026quot;North Dakota\u0026quot;,\u0026quot;West Virginia\u0026quot;,\u0026quot;Wyoming\u0026quot;,\u0026quot;Maryland\u0026quot;,\u0026quot;Nebraska\u0026quot;,\u0026quot;Maine\u0026quot;,\u0026quot;Idaho\u0026quot;,\u0026quot;Nevada\u0026quot;,\u0026quot;Montana\u0026quot;,\u0026quot;Kansas\u0026quot;,\u0026quot;Rhode Island\u0026quot;,\u0026quot;Oklahoma\u0026quot;,\u0026quot;Vermont\u0026quot;,\u0026quot;South Dakota\u0026quot;,\u0026quot;Arkansas\u0026quot;,\u0026quot;New Hampshire\u0026quot;,\u0026quot;Delaware\u0026quot;) #Changing row names to the states listed above row.names(GDP_ALL) \u0026lt;- value #column names are changed to years 2003-2019 colnames(GDP_ALL) \u0026lt;- c(\u0026quot;2003\u0026quot;, \u0026quot;2004\u0026quot;, \u0026quot;2005\u0026quot;, \u0026quot;2006\u0026quot;, \u0026quot;2007\u0026quot;, \u0026quot;2008\u0026quot;, \u0026quot;2009\u0026quot;, \u0026quot;2010\u0026quot;, \u0026quot;2011\u0026quot;, \u0026quot;2012\u0026quot;, \u0026quot;2013\u0026quot;, \u0026quot;2014\u0026quot;, \u0026quot;2015\u0026quot;, \u0026quot;2016\u0026quot;, \u0026quot;2017\u0026quot;, \u0026quot;2018\u0026quot;, \u0026quot;2019\u0026quot;) #Part 1: Map of States #To create each map, new datasets were created for each year, variables are renamed and columns are erased. This was done 17 times for years 2003 to 2019 ####### 2003 Year2003 \u0026lt;- data.frame(GDP_ALL[,1]) Year2003$year \u0026lt;- 2003 Year2003$GDP \u0026lt;- Year2003$GDP_ALL...1. Year2003$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2003 = select(Year2003, -c(\u0026quot;GDP_ALL...1.\u0026quot;)) ####### 2004 Year2004 \u0026lt;- data.frame(GDP_ALL[,2]) Year2004$year \u0026lt;- 2004 Year2004$GDP \u0026lt;- Year2004[,1] Year2004$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2004 = Year2004[,-1] ######### 2005 Year2005 \u0026lt;- data.frame(GDP_ALL[,3]) Year2005$year \u0026lt;- 2005 Year2005$GDP \u0026lt;- Year2005[,1] Year2005$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2005 = Year2005[,-1] ######### 2006 Year2006 \u0026lt;- data.frame(GDP_ALL[,4]) Year2006$year \u0026lt;- 2006 Year2006$GDP \u0026lt;- Year2006[,1] Year2006$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2006 = Year2006[,-1] ######### 2007 Year2007 \u0026lt;- data.frame(GDP_ALL[,5]) Year2007$year \u0026lt;- 2007 Year2007$GDP \u0026lt;- Year2007[,1] Year2007$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2007 = Year2007[,-1] ######### 2008 Year2008 \u0026lt;- data.frame(GDP_ALL[,6]) Year2008$year \u0026lt;- 2008 Year2008$GDP \u0026lt;- Year2008[,1] Year2008$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2008 = Year2008[,-1] ######### 2009 Year2009 \u0026lt;- data.frame(GDP_ALL[,7]) Year2009$year \u0026lt;- 2009 Year2009$GDP \u0026lt;- Year2009[,1] Year2009$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2009 = Year2009[,-1] ######### 2010 Year2010 \u0026lt;- data.frame(GDP_ALL[,8]) Year2010$year \u0026lt;- 2010 Year2010$GDP \u0026lt;- Year2010[,1] Year2010$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2010 = Year2010[,-1] ######### 2011 Year2011 \u0026lt;- data.frame(GDP_ALL[,9]) Year2011$year \u0026lt;- 2011 Year2011$GDP \u0026lt;- Year2011[,1] Year2011$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2011 = Year2011[,-1] ######### 2012 Year2012 \u0026lt;- data.frame(GDP_ALL[,10]) Year2012$year \u0026lt;- 2012 Year2012$GDP \u0026lt;- Year2012[,1] Year2012$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2012 = Year2012[,-1] ######### 2013 Year2013 \u0026lt;- data.frame(GDP_ALL[,11]) Year2013$year \u0026lt;- 2013 Year2013$GDP \u0026lt;- Year2013[,1] Year2013$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2013 = Year2013[,-1] ######### 2014 Year2014 \u0026lt;- data.frame(GDP_ALL[,12]) Year2014$year \u0026lt;- 2014 Year2014$GDP \u0026lt;- Year2014[,1] Year2014$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2014 = Year2014[,-1] ######### 2015 Year2015 \u0026lt;- data.frame(GDP_ALL[,13]) Year2015$year \u0026lt;- 2015 Year2015$GDP \u0026lt;- Year2015[,1] Year2015$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2015 = Year2015[,-1] ######### 2016 Year2016 \u0026lt;- data.frame(GDP_ALL[,14]) Year2016$year \u0026lt;- 2016 Year2016$GDP \u0026lt;- Year2016[,1] Year2016$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2016 = Year2016[,-1] ######### 2017 Year2017 \u0026lt;- data.frame(GDP_ALL[,15]) Year2017$year \u0026lt;- 2017 Year2017$GDP \u0026lt;- Year2017[,1] Year2017$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2017 = Year2017[,-1] ######### 2018 Year2018 \u0026lt;- data.frame(GDP_ALL[,16]) Year2018$year \u0026lt;- 2018 Year2018$GDP \u0026lt;- Year2018[,1] Year2018$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2018 = Year2018[,-1] ######### 2019 Year2019 \u0026lt;- data.frame(GDP_ALL[,17]) Year2019$year \u0026lt;- 2019 Year2019$GDP \u0026lt;- Year2019[,1] Year2019$state \u0026lt;- c(\u0026quot;california\u0026quot;, \u0026quot;texas\u0026quot;, \u0026quot;new york\u0026quot;,\u0026quot;florida\u0026quot;,\u0026quot;ohio\u0026quot;, \u0026quot;washington\u0026quot;, \u0026quot;colorado\u0026quot;,\u0026quot;michigan\u0026quot;, \u0026quot;massachusetts\u0026quot;,\u0026quot;arizona\u0026quot;,\u0026quot;hawaii\u0026quot;,\u0026quot;pennsylvania\u0026quot;,\u0026quot;new jersey\u0026quot;,\u0026quot;illinois\u0026quot;,\u0026quot;north carolina\u0026quot;,\u0026quot;alabama\u0026quot;,\u0026quot;missouri\u0026quot;,\u0026quot;louisiana\u0026quot;,\u0026quot;wisconsin\u0026quot;,\u0026quot;minnesota\u0026quot;,\u0026quot;oregon\u0026quot;,\u0026quot;mississippi\u0026quot;,\u0026quot;south carolina\u0026quot;,\u0026quot;connecticut\u0026quot;,\u0026quot;indiana\u0026quot;,\u0026quot;tennessee\u0026quot;,\u0026quot;kentucky\u0026quot;,\u0026quot;alaska\u0026quot;, \u0026quot;district of columbia\u0026quot;,\u0026quot;georgia\u0026quot;,\u0026quot;virginia\u0026quot;,\u0026quot;utah\u0026quot;,\u0026quot;iowa\u0026quot;,\u0026quot;new mexico\u0026quot;,\u0026quot;north dakota\u0026quot;,\u0026quot;west virginia\u0026quot;,\u0026quot;wyoming\u0026quot;,\u0026quot;maryland\u0026quot;,\u0026quot;nebraska\u0026quot;,\u0026quot;maine\u0026quot;,\u0026quot;idaho\u0026quot;,\u0026quot;nevada\u0026quot;,\u0026quot;montana\u0026quot;,\u0026quot;kansas\u0026quot;,\u0026quot;rhode island\u0026quot;,\u0026quot;oklahoma\u0026quot;,\u0026quot;vermont\u0026quot;,\u0026quot;south dakota\u0026quot;,\u0026quot;arkansas\u0026quot;,\u0026quot;new hampshire\u0026quot;,\u0026quot;delaware\u0026quot;) Year2019 = Year2019[,-1] ######################################################################### #Rows from seperate datasets are bound together GroupTable \u0026lt;- bind_rows(Year2003,Year2004,Year2005,Year2006,Year2007,Year2008,Year2009,Year2010,Year2011,Year2012,Year2013,Year2014,Year2015,Year2016,Year2017,Year2018,Year2019, .id = \u0026quot;df\u0026quot;) #Using this function I was able to derive Long and Lat values for each state MainStates \u0026lt;- map_data(\u0026quot;state\u0026quot;) MainStates$state \u0026lt;- MainStates$region merged = GroupTable %\u0026gt;% inner_join(MainStates, by = \u0026quot;state\u0026quot;) #Function was designed to create a facet_wrap with ggplot meaning separate maps for separate years to show any trends over time. This functionality makes time series analyses easier p \u0026lt;- ggplot() p0 \u0026lt;- p + geom_polygon (data=merged, aes( x = long, y = lat, group = group, fill= GDP), color = \u0026quot;white\u0026quot;, size = 0.2) p1 \u0026lt;- p0 + geom_polygon(color = \u0026quot;gray90\u0026quot;, size = 0.05) + coord_map(projection = \u0026quot;albers\u0026quot;, lat0 = 39, lat1 = 45) p2 \u0026lt;- p1 + scale_fill_viridis_c(option = \u0026quot;plasma\u0026quot;) p2 + theme_map() + facet_wrap(~ year, ncol = 3) + theme(legend.position = \u0026quot;bottom\u0026quot;, strip.background = element_blank()) + labs(fill = \u0026quot;Total Annual GDP\u0026quot;, title = \u0026quot;Total GDP by Year and by State, 2003-2019\u0026quot;)  [This analysis was done to visualize Total GDP spread by state through years 2003 - 2019. Given the mass of data, the visualizations are a bit smaller than anticipated but general trends are: California has the highest total GDP of all states and this increases by the year as shown by the increased yellow tint, Texas appears to have the second highest total GDP in comparison with an increasing trend through the years.]\nTotal GDP by State by Year, A Heat Map z = ztable(GDP_ALL) makeHeatmap(z) [This analysis is much easier to read than the map above. Using the heat map we can easily see that California has the highest GDP of all states for every year, followed by Texas and New York. The general trend is an increase in total GDP from 2003 to 2019.]\n  ","date":1597104000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597195112,"objectID":"a41400ba3c13d5388904ad4678f2651e","permalink":"/post/connecting-to-fred-data/","publishdate":"2020-08-11T00:00:00Z","relpermalink":"/post/connecting-to-fred-data/","section":"post","summary":"Reading in Data From FRED #install.packages(\u0026quot;modelr\u0026quot;) #install.packages(\u0026quot;FinCal\u0026quot;) #install.packages(\u0026quot;dplyr\u0026quot;) #install.packages(\u0026quot;FinancialMath\u0026quot;) #install.packages(\u0026quot;devtools\u0026quot;) #install.packages(\u0026quot;tidyverse\u0026quot;) #install.packages(\u0026quot;dplyr\u0026quot;) #install.packages(\u0026quot;ggpubr\u0026quot;) #install.packages(\u0026quot;epitools\u0026quot;) #install.packages(\u0026quot;data.table\u0026quot;) #install.packages(\u0026quot;usmap\u0026quot;) #install.packages(\u0026quot;maps\u0026quot;) #install.packages(\u0026quot;cowplot\u0026quot;) #install.packages(\u0026quot;ztable\u0026quot;) library(\u0026quot;modelr\u0026quot;) library(\u0026quot;FinCal\u0026quot;) library(\u0026quot;dplyr\u0026quot;) ## ## Attaching package: \u0026#39;dplyr\u0026#39; ## The following objects are masked from \u0026#39;package:stats\u0026#39;: ## ## filter, lag ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## intersect, setdiff, setequal, union library(\u0026quot;FinancialMath\u0026quot;) library(\u0026quot;ggplot2\u0026quot;) library(\u0026quot;quantmod\u0026quot;) ## Loading required package: xts ## Warning: package \u0026#39;xts\u0026#39; was built under R version 3.","tags":[],"title":"Connecting to FRED Data","type":"post"},{"authors":[],"categories":[],"content":" Shiny From R #install.packages(\u0026quot;modelr\u0026quot;) #install.packages(\u0026quot;FinCal\u0026quot;) #install.packages(\u0026quot;dplyr\u0026quot;) #install.packages(\u0026quot;FinancialMath\u0026quot;) library(\u0026quot;modelr\u0026quot;) library(\u0026quot;FinCal\u0026quot;) library(\u0026quot;dplyr\u0026quot;) ## ## Attaching package: \u0026#39;dplyr\u0026#39; ## The following objects are masked from \u0026#39;package:stats\u0026#39;: ## ## filter, lag ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## intersect, setdiff, setequal, union library(\u0026quot;FinancialMath\u0026quot;) library(\u0026quot;ggplot2\u0026quot;)  ","date":1595808000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595896104,"objectID":"9edd93f8e7c8d615493763b39c56ada4","permalink":"/post/introduction-to-shiny/","publishdate":"2020-07-27T00:00:00Z","relpermalink":"/post/introduction-to-shiny/","section":"post","summary":" Shiny From R #install.packages(\u0026quot;modelr\u0026quot;) #install.packages(\u0026quot;FinCal\u0026quot;) #install.packages(\u0026quot;dplyr\u0026quot;) #install.packages(\u0026quot;FinancialMath\u0026quot;) library(\u0026quot;modelr\u0026quot;) library(\u0026quot;FinCal\u0026quot;) library(\u0026quot;dplyr\u0026quot;) ## ## Attaching package: \u0026#39;dplyr\u0026#39; ## The following objects are masked from \u0026#39;package:stats\u0026#39;: ## ## filter, lag ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## intersect, setdiff, setequal, union library(\u0026quot;FinancialMath\u0026quot;) library(\u0026quot;ggplot2\u0026quot;)  ","tags":[],"title":"Connecting to Data on FRED (Federal Reserve)","type":"post"},{"authors":[],"categories":[],"content":" Time Value of Money Understanding the time value of money is essential to finance. The value of something is not a static but dynamic thing. Dating back as far as 5000 BC, this concept is the foundation of modern day finance (https://www.encyclopedia.com/finance/encyclopedias-almanacs-transcripts-and-maps/time-value-money). Thankfully R makes calculations for TVM easy and efficient. TVM calculations are broken down into 4 topicsL Future Value, Present Value, Rates of Return and Amortization.\n#install.packages(\u0026quot;modelr\u0026quot;) #install.packages(\u0026quot;FinCal\u0026quot;) #install.packages(\u0026quot;dplyr\u0026quot;) #install.packages(\u0026quot;FinancialMath\u0026quot;) library(\u0026quot;modelr\u0026quot;) library(\u0026quot;FinCal\u0026quot;) library(\u0026quot;dplyr\u0026quot;) ## ## Attaching package: \u0026#39;dplyr\u0026#39; ## The following objects are masked from \u0026#39;package:stats\u0026#39;: ## ## filter, lag ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## intersect, setdiff, setequal, union library(\u0026quot;FinancialMath\u0026quot;) library(\u0026quot;ggplot2\u0026quot;)  Future Value and Present Value #Below is random cash flow data I have added for these exercises. We are going to assume our invesment period is 8 years, interest is 10%, and this is an ordinary annunity cash_flow \u0026lt;- c(-10023,-84949,-84940,-83838,-93838,-73839,-83383,-102939) i = 1.10 #Manual calculation of FV (cash_flow[1] * i ^ 7) + (cash_flow[2] * i ^ 6) + (cash_flow[3] * i ^ 5) + (cash_flow[4] * i ^ 4) + (cash_flow[5] * i ^ 3) + (cash_flow[6] * i ^ 2) + (cash_flow[7] * i ^ 1) + (cash_flow[8]) ## [1] -838472.1 #R makes this calculation much easier fv.uneven(.1,cash_flow) ## [1] 838472.1 #FV of Annuity Due. Int = 10%, T = 8, type = 1 which means payment at the beginning of each period fv(.10,8,pv = 0, pmt = 1000, 1) ## [1] -12579.48  #Manual Calculation of PV (cash_flow[1]/ (i) ^ 1) + (cash_flow[2] / i ^ 2) + (cash_flow[3] / i ^ 3) + (cash_flow[4] / i ^ 4) + (cash_flow[5] / i ^ 5) + (cash_flow[6] / i ^ 6) + (cash_flow[7] / i ^ 7) + (cash_flow[8] / i ^ 8) ## [1] -391153.4  #Again R makes PV calculation easier pv.uneven(.1, cash_flow) ## [1] 391153.4  #PV of Annuity Due. Int = 10%, T = 8, type = 1 which means payment at the beginning of each period pv(.1,8, fv = 0, pmt = 1000, type = 1) ## [1] -5868.419  Rates of Return #Calculating Rates of Return in R FV = 149374838 PV = 84933 N = 89 M = 4 # number of compounding periods Iper = .1 #Calculating annualized returns manually. Couldnt find a function for this in R return = (FV/PV) ^ 1/N - 1 return ## [1] 18.76109 #Finding the EAR. EAR = (1 + Iper/M)^M - 1 EAR ## [1] 0.1038129 #Amortization Tablesin R\n#Add Numbers to Values to Quick Calculations FV = 0 PV = 300000 N = 30 M = 12 # frequency of payments per year Iper = .023 #Step 1 find the PMT PMT = -pmt(Iper/M,N*M,PV,FV,type = 0) PMT ## [1] 1154.404 #Step 2 create the data frame Amort \u0026lt;- data.frame(payment = 1:360) #Step 3 assign beginning value to start loop Amort[1,2] \u0026lt;- PV #Step 4 Create for loop to fill in amortization table for(i in 1:360){ #number of periods is 360 Amort[i,3] \u0026lt;- Amort[i,2] * Iper/12 #Interest Paid is Beginning Balance x Interest Rate Amort[i,4] \u0026lt;- PMT - Amort[i,3] #Priciple Paid is equal to the Payment minus Interest Paid Amort[i,5] \u0026lt;- Amort[i,2] - Amort[i,4] #Ending Balance is equal to the Beginning Balance minus the Principle Paid Amort[i + 1,2]\u0026lt;- Amort[i,5] #Assign Beginning Balance as last payments Ending Balance } #Add column names names(Amort)[2]\u0026lt;- \u0026#39;Beginning Balance\u0026#39; names(Amort)[3]\u0026lt;- \u0026#39;Interest Paid\u0026#39; names(Amort)[4]\u0026lt;- \u0026#39;Principle Paid\u0026#39; names(Amort)[5]\u0026lt;- \u0026#39;Ending Balance\u0026#39; #View the finished table head(Amort) ## payment Beginning Balance Interest Paid Principle Paid Ending Balance ## 1 1 300000.0 575.0000 579.4039 299420.6 ## 2 2 299420.6 573.8895 580.5144 298840.1 ## 3 3 298840.1 572.7768 581.6270 298258.5 ## 4 4 298258.5 571.6620 582.7418 297675.7 ## 5 5 297675.7 570.5451 583.8588 297091.9 ## 6 6 297091.9 569.4261 584.9778 296506.9 #I created this amortization using a for loop, but fortunately R has a package for this #Amort.table function in R amort_table \u0026lt;- amort.table(Loan=PV,n=360,i=Iper,ic=12,pf=12) head(amort_table[\u0026quot;Schedule\u0026quot;], n = 10L) ## $Schedule ## Year Payment Interest Paid Principal Paid Balance ## 1 0.08 1154.4 575.00 579.40 299420.60 ## 2 0.17 1154.4 573.89 580.51 298840.08 ## 3 0.25 1154.4 572.78 581.63 298258.45 ## 4 0.33 1154.4 571.66 582.74 297675.71 ## 5 0.42 1154.4 570.55 583.86 297091.85 ## 6 0.50 1154.4 569.43 584.98 296506.88 ## 7 0.58 1154.4 568.30 586.10 295920.78 ## 8 0.67 1154.4 567.18 587.22 295333.55 ## 9 0.75 1154.4 566.06 588.35 294745.21 ## 10 0.83 1154.4 564.93 589.48 294155.73 ## 11 0.92 1154.4 563.80 590.61 293565.13 ## 12 1.00 1154.4 562.67 591.74 292973.39 ## 13 1.08 1154.4 561.53 592.87 292380.52 ## 14 1.17 1154.4 560.40 594.01 291786.51 ## 15 1.25 1154.4 559.26 595.15 291191.36 ## 16 1.33 1154.4 558.12 596.29 290595.08 ## 17 1.42 1154.4 556.97 597.43 289997.65 ## 18 1.50 1154.4 555.83 598.58 289399.07 ## 19 1.58 1154.4 554.68 599.72 288799.35 ## 20 1.67 1154.4 553.53 600.87 288198.48 ## 21 1.75 1154.4 552.38 602.02 287596.45 ## 22 1.83 1154.4 551.23 603.18 286993.28 ## 23 1.92 1154.4 550.07 604.33 286388.94 ## 24 2.00 1154.4 548.91 605.49 285783.45 ## 25 2.08 1154.4 547.75 606.65 285176.80 ## 26 2.17 1154.4 546.59 607.82 284568.98 ## 27 2.25 1154.4 545.42 608.98 283960.00 ## 28 2.33 1154.4 544.26 610.15 283349.86 ## 29 2.42 1154.4 543.09 611.32 282738.54 ## 30 2.50 1154.4 541.92 612.49 282126.05 ## 31 2.58 1154.4 540.74 613.66 281512.39 ## 32 2.67 1154.4 539.57 614.84 280897.55 ## 33 2.75 1154.4 538.39 616.02 280281.53 ## 34 2.83 1154.4 537.21 617.20 279664.34 ## 35 2.92 1154.4 536.02 618.38 279045.96 ## 36 3.00 1154.4 534.84 619.57 278426.39 ## 37 3.08 1154.4 533.65 620.75 277805.64 ## 38 3.17 1154.4 532.46 621.94 277183.69 ## 39 3.25 1154.4 531.27 623.14 276560.56 ## 40 3.33 1154.4 530.07 624.33 275936.23 ## 41 3.42 1154.4 528.88 625.53 275310.70 ## 42 3.50 1154.4 527.68 626.73 274683.98 ## 43 3.58 1154.4 526.48 627.93 274056.05 ## 44 3.67 1154.4 525.27 629.13 273426.92 ## 45 3.75 1154.4 524.07 630.34 272796.59 ## 46 3.83 1154.4 522.86 631.54 272165.04 ## 47 3.92 1154.4 521.65 632.75 271532.29 ## 48 4.00 1154.4 520.44 633.97 270898.32 ## 49 4.08 1154.4 519.22 635.18 270263.14 ## 50 4.17 1154.4 518.00 636.40 269626.74 ## 51 4.25 1154.4 516.78 637.62 268989.12 ## 52 4.33 1154.4 515.56 638.84 268350.28 ## 53 4.42 1154.4 514.34 640.07 267710.21 ## 54 4.50 1154.4 513.11 641.29 267068.92 ## 55 4.58 1154.4 511.88 642.52 266426.40 ## 56 4.67 1154.4 510.65 643.75 265782.65 ## 57 4.75 1154.4 509.42 644.99 265137.66 ## 58 4.83 1154.4 508.18 646.22 264491.43 ## 59 4.92 1154.4 506.94 647.46 263843.97 ## 60 5.00 1154.4 505.70 648.70 263195.27 ## 61 5.08 1154.4 504.46 649.95 262545.32 ## 62 5.17 1154.4 503.21 651.19 261894.13 ## 63 5.25 1154.4 501.96 652.44 261241.69 ## 64 5.33 1154.4 500.71 653.69 260588.00 ## 65 5.42 1154.4 499.46 654.94 259933.06 ## 66 5.50 1154.4 498.21 656.20 259276.86 ## 67 5.58 1154.4 496.95 657.46 258619.40 ## 68 5.67 1154.4 495.69 658.72 257960.69 ## 69 5.75 1154.4 494.42 659.98 257300.71 ## 70 5.83 1154.4 493.16 661.24 256639.46 ## 71 5.92 1154.4 491.89 662.51 255976.95 ## 72 6.00 1154.4 490.62 663.78 255313.17 ## 73 6.08 1154.4 489.35 665.05 254648.12 ## 74 6.17 1154.4 488.08 666.33 253981.79 ## 75 6.25 1154.4 486.80 667.61 253314.18 ## 76 6.33 1154.4 485.52 668.89 252645.30 ## 77 6.42 1154.4 484.24 670.17 251975.13 ## 78 6.50 1154.4 482.95 671.45 251303.68 ## 79 6.58 1154.4 481.67 672.74 250630.94 ## 80 6.67 1154.4 480.38 674.03 249956.91 ## 81 6.75 1154.4 479.08 675.32 249281.59 ## 82 6.83 1154.4 477.79 676.61 248604.98 ## 83 6.92 1154.4 476.49 677.91 247927.07 ## 84 7.00 1154.4 475.19 679.21 247247.86 ## 85 7.08 1154.4 473.89 680.51 246567.34 ## 86 7.17 1154.4 472.59 681.82 245885.53 ## 87 7.25 1154.4 471.28 683.12 245202.40 ## 88 7.33 1154.4 469.97 684.43 244517.97 ## 89 7.42 1154.4 468.66 685.74 243832.23 ## 90 7.50 1154.4 467.35 687.06 243145.17 ## 91 7.58 1154.4 466.03 688.38 242456.79 ## 92 7.67 1154.4 464.71 689.70 241767.10 ## 93 7.75 1154.4 463.39 691.02 241076.08 ## 94 7.83 1154.4 462.06 692.34 240383.74 ## 95 7.92 1154.4 460.74 693.67 239690.07 ## 96 8.00 1154.4 459.41 695.00 238995.07 ## 97 8.08 1154.4 458.07 696.33 238298.74 ## 98 8.17 1154.4 456.74 697.66 237601.08 ## 99 8.25 1154.4 455.40 699.00 236902.08 ## 100 8.33 1154.4 454.06 700.34 236201.74 ## 101 8.42 1154.4 452.72 701.68 235500.05 ## 102 8.50 1154.4 451.38 703.03 234797.02 ## 103 8.58 1154.4 450.03 704.38 234092.65 ## 104 8.67 1154.4 448.68 705.73 233386.92 ## 105 8.75 1154.4 447.32 707.08 232679.84 ## 106 8.83 1154.4 445.97 708.43 231971.41 ## 107 8.92 1154.4 444.61 709.79 231261.61 ## 108 9.00 1154.4 443.25 711.15 230550.46 ## 109 9.08 1154.4 441.89 712.52 229837.95 ## 110 9.17 1154.4 440.52 713.88 229124.07 ## 111 9.25 1154.4 439.15 715.25 228408.82 ## 112 9.33 1154.4 437.78 716.62 227692.20 ## 113 9.42 1154.4 436.41 717.99 226974.20 ## 114 9.50 1154.4 435.03 719.37 226254.83 ## 115 9.58 1154.4 433.66 720.75 225534.08 ## 116 9.67 1154.4 432.27 722.13 224811.95 ## 117 9.75 1154.4 430.89 723.51 224088.44 ## 118 9.83 1154.4 429.50 724.90 223363.54 ## 119 9.92 1154.4 428.11 726.29 222637.25 ## 120 10.00 1154.4 426.72 727.68 221909.57 ## 121 10.08 1154.4 425.33 729.08 221180.49 ## 122 10.17 1154.4 423.93 730.47 220450.01 ## 123 10.25 1154.4 422.53 731.87 219718.14 ## 124 10.33 1154.4 421.13 733.28 218984.86 ## 125 10.42 1154.4 419.72 734.68 218250.18 ## 126 10.50 1154.4 418.31 736.09 217514.09 ## 127 10.58 1154.4 416.90 737.50 216776.59 ## 128 10.67 1154.4 415.49 738.92 216037.67 ## 129 10.75 1154.4 414.07 740.33 215297.34 ## 130 10.83 1154.4 412.65 741.75 214555.59 ## 131 10.92 1154.4 411.23 743.17 213812.42 ## 132 11.00 1154.4 409.81 744.60 213067.82 ## 133 11.08 1154.4 408.38 746.02 212321.79 ## 134 11.17 1154.4 406.95 747.45 211574.34 ## 135 11.25 1154.4 405.52 748.89 210825.45 ## 136 11.33 1154.4 404.08 750.32 210075.13 ## 137 11.42 1154.4 402.64 751.76 209323.37 ## 138 11.50 1154.4 401.20 753.20 208570.17 ## 139 11.58 1154.4 399.76 754.64 207815.53 ## 140 11.67 1154.4 398.31 756.09 207059.44 ## 141 11.75 1154.4 396.86 757.54 206301.90 ## 142 11.83 1154.4 395.41 758.99 205542.91 ## 143 11.92 1154.4 393.96 760.45 204782.46 ## 144 12.00 1154.4 392.50 761.90 204020.55 ## 145 12.08 1154.4 391.04 763.36 203257.19 ## 146 12.17 1154.4 389.58 764.83 202492.36 ## 147 12.25 1154.4 388.11 766.29 201726.07 ## 148 12.33 1154.4 386.64 767.76 200958.31 ## 149 12.42 1154.4 385.17 769.23 200189.07 ## 150 12.50 1154.4 383.70 770.71 199418.36 ## 151 12.58 1154.4 382.22 772.19 198646.18 ## 152 12.67 1154.4 380.74 773.67 197872.51 ## 153 12.75 1154.4 379.26 775.15 197097.37 ## 154 12.83 1154.4 377.77 776.63 196320.73 ## 155 12.92 1154.4 376.28 778.12 195542.61 ## 156 13.00 1154.4 374.79 779.61 194763.00 ## 157 13.08 1154.4 373.30 781.11 193981.89 ## 158 13.17 1154.4 371.80 782.61 193199.28 ## 159 13.25 1154.4 370.30 784.11 192415.18 ## 160 13.33 1154.4 368.80 785.61 191629.57 ## 161 13.42 1154.4 367.29 787.11 190842.45 ## 162 13.50 1154.4 365.78 788.62 190053.83 ## 163 13.58 1154.4 364.27 790.13 189263.70 ## 164 13.67 1154.4 362.76 791.65 188472.05 ## 165 13.75 1154.4 361.24 793.17 187678.88 ## 166 13.83 1154.4 359.72 794.69 186884.20 ## 167 13.92 1154.4 358.19 796.21 186087.99 ## 168 14.00 1154.4 356.67 797.74 185290.25 ## 169 14.08 1154.4 355.14 799.26 184490.99 ## 170 14.17 1154.4 353.61 800.80 183690.19 ## 171 14.25 1154.4 352.07 802.33 182887.86 ## 172 14.33 1154.4 350.54 803.87 182083.99 ## 173 14.42 1154.4 348.99 805.41 181278.58 ## 174 14.50 1154.4 347.45 806.95 180471.63 ## 175 14.58 1154.4 345.90 808.50 179663.13 ## 176 14.67 1154.4 344.35 810.05 178853.08 ## 177 14.75 1154.4 342.80 811.60 178041.48 ## 178 14.83 1154.4 341.25 813.16 177228.32 ## 179 14.92 1154.4 339.69 814.72 176413.61 ## 180 15.00 1154.4 338.13 816.28 175597.33 ## 181 15.08 1154.4 336.56 817.84 174779.49 ## 182 15.17 1154.4 334.99 819.41 173960.08 ## 183 15.25 1154.4 333.42 820.98 173139.09 ## 184 15.33 1154.4 331.85 822.55 172316.54 ## 185 15.42 1154.4 330.27 824.13 171492.41 ## 186 15.50 1154.4 328.69 825.71 170666.70 ## 187 15.58 1154.4 327.11 827.29 169839.41 ## 188 15.67 1154.4 325.53 828.88 169010.53 ## 189 15.75 1154.4 323.94 830.47 168180.06 ## 190 15.83 1154.4 322.35 832.06 167348.00 ## 191 15.92 1154.4 320.75 833.65 166514.35 ## 192 16.00 1154.4 319.15 835.25 165679.10 ## 193 16.08 1154.4 317.55 836.85 164842.25 ## 194 16.17 1154.4 315.95 838.46 164003.79 ## 195 16.25 1154.4 314.34 840.06 163163.73 ## 196 16.33 1154.4 312.73 841.67 162322.05 ## 197 16.42 1154.4 311.12 843.29 161478.77 ## 198 16.50 1154.4 309.50 844.90 160633.86 ## 199 16.58 1154.4 307.88 846.52 159787.34 ## 200 16.67 1154.4 306.26 848.14 158939.20 ## 201 16.75 1154.4 304.63 849.77 158089.43 ## 202 16.83 1154.4 303.00 851.40 157238.03 ## 203 16.92 1154.4 301.37 853.03 156385.00 ## 204 17.00 1154.4 299.74 854.67 155530.33 ## 205 17.08 1154.4 298.10 856.30 154674.03 ## 206 17.17 1154.4 296.46 857.95 153816.08 ## 207 17.25 1154.4 294.81 859.59 152956.49 ## 208 17.33 1154.4 293.17 861.24 152095.25 ## 209 17.42 1154.4 291.52 862.89 151232.37 ## 210 17.50 1154.4 289.86 864.54 150367.82 ## 211 17.58 1154.4 288.20 866.20 149501.63 ## 212 17.67 1154.4 286.54 867.86 148633.77 ## 213 17.75 1154.4 284.88 869.52 147764.24 ## 214 17.83 1154.4 283.21 871.19 146893.05 ## 215 17.92 1154.4 281.55 872.86 146020.20 ## 216 18.00 1154.4 279.87 874.53 145145.66 ## 217 18.08 1154.4 278.20 876.21 144269.46 ## 218 18.17 1154.4 276.52 877.89 143391.57 ## 219 18.25 1154.4 274.83 879.57 142512.00 ## 220 18.33 1154.4 273.15 881.26 141630.74 ## 221 18.42 1154.4 271.46 882.94 140747.80 ## 222 18.50 1154.4 269.77 884.64 139863.16 ## 223 18.58 1154.4 268.07 886.33 138976.83 ## 224 18.67 1154.4 266.37 888.03 138088.80 ## 225 18.75 1154.4 264.67 889.73 137199.06 ## 226 18.83 1154.4 262.96 891.44 136307.62 ## 227 18.92 1154.4 261.26 893.15 135414.48 ## 228 19.00 1154.4 259.54 894.86 134519.62 ## 229 19.08 1154.4 257.83 896.57 133623.04 ## 230 19.17 1154.4 256.11 898.29 132724.75 ## 231 19.25 1154.4 254.39 900.01 131824.73 ## 232 19.33 1154.4 252.66 901.74 130922.99 ## 233 19.42 1154.4 250.94 903.47 130019.53 ## 234 19.50 1154.4 249.20 905.20 129114.33 ## 235 19.58 1154.4 247.47 906.93 128207.39 ## 236 19.67 1154.4 245.73 908.67 127298.72 ## 237 19.75 1154.4 243.99 910.41 126388.30 ## 238 19.83 1154.4 242.24 912.16 125476.14 ## 239 19.92 1154.4 240.50 913.91 124562.24 ## 240 20.00 1154.4 238.74 915.66 123646.58 ## 241 20.08 1154.4 236.99 917.41 122729.16 ## 242 20.17 1154.4 235.23 919.17 121809.99 ## 243 20.25 1154.4 233.47 920.93 120889.05 ## 244 20.33 1154.4 231.70 922.70 119966.35 ## 245 20.42 1154.4 229.94 924.47 119041.89 ## 246 20.50 1154.4 228.16 926.24 118115.65 ## 247 20.58 1154.4 226.39 928.02 117187.63 ## 248 20.67 1154.4 224.61 929.79 116257.84 ## 249 20.75 1154.4 222.83 931.58 115326.26 ## 250 20.83 1154.4 221.04 933.36 114392.90 ## 251 20.92 1154.4 219.25 935.15 113457.75 ## 252 21.00 1154.4 217.46 936.94 112520.80 ## 253 21.08 1154.4 215.66 938.74 111582.06 ## 254 21.17 1154.4 213.87 940.54 110641.53 ## 255 21.25 1154.4 212.06 942.34 109699.19 ## 256 21.33 1154.4 210.26 944.15 108755.04 ## 257 21.42 1154.4 208.45 945.96 107809.08 ## 258 21.50 1154.4 206.63 947.77 106861.31 ## 259 21.58 1154.4 204.82 949.59 105911.73 ## 260 21.67 1154.4 203.00 951.41 104960.32 ## 261 21.75 1154.4 201.17 953.23 104007.09 ## 262 21.83 1154.4 199.35 955.06 103052.03 ## 263 21.92 1154.4 197.52 956.89 102095.14 ## 264 22.00 1154.4 195.68 958.72 101136.42 ## 265 22.08 1154.4 193.84 960.56 100175.86 ## 266 22.17 1154.4 192.00 962.40 99213.46 ## 267 22.25 1154.4 190.16 964.24 98249.22 ## 268 22.33 1154.4 188.31 966.09 97283.13 ## 269 22.42 1154.4 186.46 967.94 96315.18 ## 270 22.50 1154.4 184.60 969.80 95345.38 ## 271 22.58 1154.4 182.75 971.66 94373.72 ## 272 22.67 1154.4 180.88 973.52 93400.20 ## 273 22.75 1154.4 179.02 975.39 92424.82 ## 274 22.83 1154.4 177.15 977.26 91447.56 ## 275 22.92 1154.4 175.27 979.13 90468.43 ## 276 23.00 1154.4 173.40 981.01 89487.42 ## 277 23.08 1154.4 171.52 982.89 88504.54 ## 278 23.17 1154.4 169.63 984.77 87519.77 ## 279 23.25 1154.4 167.75 986.66 86533.11 ## 280 23.33 1154.4 165.86 988.55 85544.56 ## 281 23.42 1154.4 163.96 990.44 84554.12 ## 282 23.50 1154.4 162.06 992.34 83561.78 ## 283 23.58 1154.4 160.16 994.24 82567.53 ## 284 23.67 1154.4 158.25 996.15 81571.38 ## 285 23.75 1154.4 156.35 998.06 80573.32 ## 286 23.83 1154.4 154.43 999.97 79573.35 ## 287 23.92 1154.4 152.52 1001.89 78571.46 ## 288 24.00 1154.4 150.60 1003.81 77567.66 ## 289 24.08 1154.4 148.67 1005.73 76561.92 ## 290 24.17 1154.4 146.74 1007.66 75554.26 ## 291 24.25 1154.4 144.81 1009.59 74544.67 ## 292 24.33 1154.4 142.88 1011.53 73533.14 ## 293 24.42 1154.4 140.94 1013.47 72519.68 ## 294 24.50 1154.4 139.00 1015.41 71504.27 ## 295 24.58 1154.4 137.05 1017.35 70486.92 ## 296 24.67 1154.4 135.10 1019.30 69467.61 ## 297 24.75 1154.4 133.15 1021.26 68446.36 ## 298 24.83 1154.4 131.19 1023.22 67423.14 ## 299 24.92 1154.4 129.23 1025.18 66397.96 ## 300 25.00 1154.4 127.26 1027.14 65370.82 ## 301 25.08 1154.4 125.29 1029.11 64341.71 ## 302 25.17 1154.4 123.32 1031.08 63310.63 ## 303 25.25 1154.4 121.35 1033.06 62277.57 ## 304 25.33 1154.4 119.37 1035.04 61242.53 ## 305 25.42 1154.4 117.38 1037.02 60205.51 ## 306 25.50 1154.4 115.39 1039.01 59166.50 ## 307 25.58 1154.4 113.40 1041.00 58125.50 ## 308 25.67 1154.4 111.41 1043.00 57082.50 ## 309 25.75 1154.4 109.41 1045.00 56037.51 ## 310 25.83 1154.4 107.41 1047.00 54990.51 ## 311 25.92 1154.4 105.40 1049.01 53941.50 ## 312 26.00 1154.4 103.39 1051.02 52890.49 ## 313 26.08 1154.4 101.37 1053.03 51837.46 ## 314 26.17 1154.4 99.36 1055.05 50782.41 ## 315 26.25 1154.4 97.33 1057.07 49725.34 ## 316 26.33 1154.4 95.31 1059.10 48666.24 ## 317 26.42 1154.4 93.28 1061.13 47605.11 ## 318 26.50 1154.4 91.24 1063.16 46541.95 ## 319 26.58 1154.4 89.21 1065.20 45476.76 ## 320 26.67 1154.4 87.16 1067.24 44409.52 ## 321 26.75 1154.4 85.12 1069.29 43340.23 ## 322 26.83 1154.4 83.07 1071.34 42268.89 ## 323 26.92 1154.4 81.02 1073.39 41195.51 ## 324 27.00 1154.4 78.96 1075.45 40120.06 ## 325 27.08 1154.4 76.90 1077.51 39042.55 ## 326 27.17 1154.4 74.83 1079.57 37962.98 ## 327 27.25 1154.4 72.76 1081.64 36881.34 ## 328 27.33 1154.4 70.69 1083.71 35797.62 ## 329 27.42 1154.4 68.61 1085.79 34711.83 ## 330 27.50 1154.4 66.53 1087.87 33623.96 ## 331 27.58 1154.4 64.45 1089.96 32534.00 ## 332 27.67 1154.4 62.36 1092.05 31441.95 ## 333 27.75 1154.4 60.26 1094.14 30347.81 ## 334 27.83 1154.4 58.17 1096.24 29251.58 ## 335 27.92 1154.4 56.07 1098.34 28153.24 ## 336 28.00 1154.4 53.96 1100.44 27052.80 ## 337 28.08 1154.4 51.85 1102.55 25950.24 ## 338 28.17 1154.4 49.74 1104.67 24845.58 ## 339 28.25 1154.4 47.62 1106.78 23738.79 ## 340 28.33 1154.4 45.50 1108.90 22629.89 ## 341 28.42 1154.4 43.37 1111.03 21518.86 ## 342 28.50 1154.4 41.24 1113.16 20405.70 ## 343 28.58 1154.4 39.11 1115.29 19290.41 ## 344 28.67 1154.4 36.97 1117.43 18172.98 ## 345 28.75 1154.4 34.83 1119.57 17053.40 ## 346 28.83 1154.4 32.69 1121.72 15931.69 ## 347 28.92 1154.4 30.54 1123.87 14807.82 ## 348 29.00 1154.4 28.38 1126.02 13681.80 ## 349 29.08 1154.4 26.22 1128.18 12553.62 ## 350 29.17 1154.4 24.06 1130.34 11423.27 ## 351 29.25 1154.4 21.89 1132.51 10290.76 ## 352 29.33 1154.4 19.72 1134.68 9156.08 ## 353 29.42 1154.4 17.55 1136.85 8019.23 ## 354 29.50 1154.4 15.37 1139.03 6880.19 ## 355 29.58 1154.4 13.19 1141.22 5738.98 ## 356 29.67 1154.4 11.00 1143.40 4595.57 ## 357 29.75 1154.4 8.81 1145.60 3449.98 ## 358 29.83 1154.4 6.61 1147.79 2302.19 ## 359 29.92 1154.4 4.41 1149.99 1152.20 ## 360 30.00 1154.4 2.21 1152.20 0.00 amort_schedule \u0026lt;- as.data.frame(amort_table[\u0026quot;Schedule\u0026quot;]) amort_schedule$period \u0026lt;- c(1:360) #From graph, ggplot(data = amort_schedule, aes(x = period, y = Schedule.Principal.Paid)) + geom_bar(stat = \u0026quot;identity\u0026quot;, color=\u0026quot;blue\u0026quot;) + labs (title = \u0026quot;Amount of Priciple Paid Over Life of Loan\u0026quot;, x = \u0026quot;Payment Period\u0026quot;, y = \u0026quot;Dollars\u0026quot;)  ","date":1595721600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595804960,"objectID":"984f0c21823ca4877957f994ff7be6bb","permalink":"/post/time-value-of-money/","publishdate":"2020-07-26T00:00:00Z","relpermalink":"/post/time-value-of-money/","section":"post","summary":"Time Value of Money Understanding the time value of money is essential to finance. The value of something is not a static but dynamic thing. Dating back as far as 5000 BC, this concept is the foundation of modern day finance (https://www.","tags":[],"title":"Time Value of Money","type":"post"},{"authors":[],"categories":[],"content":"This post will center on simple stock portfolio risk and return analysis using R Install all necessary packages. #install.packages(\u0026quot;tidyquant\u0026quot;) #install.packages(\u0026quot;timetk\u0026quot;) #install.packages(\u0026quot;plyr\u0026quot;) #install.packages(\u0026quot;knitr\u0026quot;) #install.packages(\u0026quot;dplyr\u0026quot;) #install.packages(\u0026quot;quantmod\u0026quot;) #install.packages(\u0026quot;BatchGetSymbols\u0026quot;) #install.packages(\u0026quot;tsbox\u0026quot;) #install.packages(\u0026quot;lubridate\u0026quot;) library(\u0026quot;tidyquant\u0026quot;) library(\u0026quot;timetk\u0026quot;) library(\u0026quot;ggplot2\u0026quot;) library(\u0026quot;plyr\u0026quot;) library(\u0026quot;knitr\u0026quot;) library(\u0026quot;dplyr\u0026quot;) library(\u0026quot;quantmod\u0026quot;) library(\u0026quot;BatchGetSymbols\u0026quot;) library(\u0026quot;tsbox\u0026quot;) library(\u0026quot;lubridate\u0026quot;)  Downloading and Plotting Daily Return Data #Data is downloaded using get_symbols function from quantmod RSP \u0026lt;- getSymbols(\u0026quot;RSP\u0026quot;, src = \u0026quot;yahoo\u0026quot;, from = '2003-04-30', to = \u0026quot;2020-07-07\u0026quot;, auto.assign = FALSE) RSP_Daily_Return \u0026lt;- dailyReturn(RSP) #Daily Stock Prices are Plotted RSP_Daily_Return %\u0026gt;% ggplot(aes(x = index(RSP_Daily_Return), y = daily.returns)) + geom_line(size=0.5, color=\u0026quot;steel blue\u0026quot;) + ggtitle(\u0026quot;Guggenheim Invest S\u0026amp;P 500 Pure Value ETF since 2003\u0026quot;) + scale_x_date(date_breaks = \u0026quot;years\u0026quot;, date_labels = \u0026quot;%Y\u0026quot;) + labs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;Adjusted Price\u0026quot;)  [ Graph of Daily Returns is difficult to interpret, but we see both extreme highs and lows during the 2008-2009 financial crisis as well as the highs and lows in 2020 during the COVID pandemic]\nViewing and Plotting Monthly Returns #Share Price Data is already downloaded using the get_symbols function from quantmod. Quantmod makes return calculations easy with monthlyReturn(). RSP_Monthly_Return \u0026lt;- monthlyReturn(RSP) #Viewing data before analysis head(RSP_Monthly_Return, n=10)  ## monthly.returns ## 2003-05-30 0.109405980 ## 2003-06-30 0.008656778 ## 2003-07-31 0.023535694 ## 2003-08-29 0.043136238 ## 2003-09-30 -0.019723212 ## 2003-10-31 0.069236656 ## 2003-11-28 0.021109961 ## 2003-12-31 0.048780522 ## 2004-01-30 0.023698842 ## 2004-02-27 0.019039376  #Plotting Monthly Return Data. RSP_Monthly_Return %\u0026gt;% ggplot(aes(x = index(RSP_Monthly_Return), y = monthly.returns)) + geom_line(size=0.5, color=\u0026quot;orange\u0026quot;) + ggtitle(\u0026quot;Guggenheim Invest S\u0026amp;P 500 Pure Value ETF Daily Return since 2003\u0026quot;) + labs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;Monthly Return\u0026quot;)  [The line graph for the monthly returns is easier to interpret than the daily return data. It appears monthly returns have been cyclical with extreme lows between the years 2008-2009 and the year 2020. Again these lows are due to both the 2008 financial crisis and the COVID pandemic respectively]\nCalculating and Plotting Annual Returns #Deriving Annula Returns. Using the yearlyReturn() function from quantmod RSP_Yearly_Return \u0026lt;- yearlyReturn(RSP) #Viewing the data head(RSP_Yearly_Return)  ## yearly.returns ## 2003-12-31 0.341089069 ## 2004-12-31 0.152897812 ## 2005-12-30 0.062563958 ## 2006-12-29 0.141204177 ## 2007-12-31 -0.003379806 ## 2008-12-31 -0.410767295  #Plotting Annual Returns with a Line Graph. RSP_Yearly_Return %\u0026gt;% ggplot(aes(x = index(RSP_Yearly_Return), y = yearly.returns)) + geom_line(size=0.5, color=\u0026quot;orange\u0026quot;) + ggtitle(\u0026quot;Guggenheim Invest S\u0026amp;P 500 Pure Value ETF Daily Return since 2003\u0026quot;) + labs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;Annual Return\u0026quot;)  #Plotting Annual Returns with Bar Graph RSP_Yearly_Return %\u0026gt;% ggplot(aes(x = index(RSP_Yearly_Return), y = yearly.returns)) + geom_bar(stat=\u0026quot;identity\u0026quot;, color=\u0026quot;orange\u0026quot;) + #stat=identity means bar represents value where as stat=bin would be equal to the number of cases which is not applicable in this case. ggtitle(\u0026quot;Guggenheim Invest S\u0026amp;P 500 Pure Value ETF Daily Return since 2003\u0026quot;) + labs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;Annual Return\u0026quot;)  [Above are a line graph and a bar graph for RSP\u0026rsquo;s annual return data. The line graph appears to exhibit quite a bit of fluctuations with more extereme values during the financial crisis of 2008 and 2020 COVID crisis. For this type of analysis, the bar graph makes interpretation easier than the line graph. It is clear, both the magnitude as well as when such flucations in annual returns occurred]\nCumulative Daily Return for RSP #Convert RSP_Daily_Return from an XTS or time series to a data frame so that we can mutate RSP_Daily_Return \u0026lt;- as.data.frame(RSP_Daily_Return) #Converting the daily return variable into a numeric data type daily.return \u0026lt;- as.numeric(RSP_Daily_Return$daily.returns) #What if I wanted to know what the cumulative return for RSP was since 2003 RSP_Cumulative_Return \u0026lt;- as.data.frame(RSP_Daily_Return) %\u0026gt;% mutate(creturn = cumprod(1 + daily.returns)-1) #(1 + r) * (1 + r)... #Index functions converts the ref.date variable from an xts to a date variable. RSP_Cumulative_Return$dates \u0026lt;- index(RSP_Daily_Return) #1$ in 2003 would be around $4.7 today RSP_Cumulative_Return %\u0026gt;% ggplot(aes(x = dates, y = creturn)) + geom_line(size=0.5, color=\u0026quot;orange\u0026quot;) + ggtitle(\u0026quot;Guggenheim Invest S\u0026amp;P 500 Pure Value ETF Daily Return since 2003\u0026quot;) + labs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;Cumulative Daily Return\u0026quot;)  [$1 in 2003 would be around $3.5 today. ]\nDownloading and Plotting Data for Multiple Stocks #the ticker symbols for multiple stock are stored in the tickers variable tickers \u0026lt;- c(\u0026quot;RSP\u0026quot;, \u0026quot;DIA\u0026quot;, \u0026quot;AAPL\u0026quot;, \u0026quot;DIS\u0026quot;, \u0026quot;GOOG\u0026quot;, \u0026quot;BAR\u0026quot;, \u0026quot;UAL\u0026quot;) #Pricing and Return Data is downloaded through the BatchGetSymbols function. Based on research I did online, this function appears to be the most efficient means of downloading stock data for muliple different stocks multiple_stocks \u0026lt;- BatchGetSymbols(tickers, first.date = '2007-01-01', last.date = \u0026quot;2020-06-30\u0026quot;, freq.data = \u0026quot;yearly\u0026quot;, # calculates annual return data type.return = \u0026quot;arit\u0026quot;, do.complete.data = FALSE, do.fill.missing.prices = TRUE, do.cache = TRUE, do.parallel = FALSE, be.quiet = FALSE) #Its important to always look at your data before you analyze head(multiple_stocks$df.tickers)  ## # A tibble: 6 x 10 ## ticker ref.date volume price.open price.high price.low price.close ## \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 AAPL 2007-01-03 6.17e10 12.3 28.5 11.9 12.0 ## 2 AAPL 2008-01-02 7.15e10 28.5 27.8 11.5 27.8 ## 3 AAPL 2009-01-02 3.58e10 12.3 30.2 11.2 13.0 ## 4 AAPL 2010-01-04 3.78e10 30.5 46.5 27.4 30.6 ## 5 AAPL 2011-01-03 3.10e10 46.5 60.3 45.0 47.1 ## 6 AAPL 2012-01-03 3.30e10 58.5 100. 58.7 58.7 ## # … with 3 more variables: price.adjusted \u0026lt;dbl\u0026gt;, ret.adjusted.prices \u0026lt;dbl\u0026gt;, ## # ret.closing.prices \u0026lt;dbl\u0026gt;  ggplot(multiple_stocks$df.tickers, aes(x = ref.date, y = price.adjusted, color = ticker)) + geom_line() + ggtitle(\u0026quot;Price chart for multiple stocks\u0026quot;)  [This line graph is the pricing data for multiple stocks. Google has the highest stock price per share with around $1500 per share today. The next highest stock price today is Apple, with DIA, an Dow Jones ETF following.]\nPlotting Daily Returns for Multiple Stocks #Would like to investigate the cumulative return of several stocks simultaneosly multiple_stocks_df \u0026lt;- data.frame(multiple_stocks$df.tickers) head(multiple_stocks_df)  ## ticker ref.date volume price.open price.high price.low price.close ## 1 AAPL 2007-01-03 61748996400 12.32714 28.54714 11.89571 11.97143 ## 2 AAPL 2008-01-02 71495301500 28.46714 27.84714 11.49857 27.83429 ## 3 AAPL 2009-01-02 35813421700 12.26857 30.23428 11.17143 12.96429 ## 4 AAPL 2010-01-04 37756231800 30.49000 46.49572 27.43571 30.57286 ## 5 AAPL 2011-01-03 31014834900 46.52000 60.32000 45.04572 47.08143 ## 6 AAPL 2012-01-03 32991051100 58.48571 100.30000 58.74714 58.74714 ## price.adjusted ret.adjusted.prices ret.closing.prices ## 1 10.36364 NA NA ## 2 24.09607 1.3250593 1.3250596 ## 3 11.22315 -0.5342334 -0.5342332 ## 4 26.46683 1.3582365 1.3582369 ## 5 40.75828 0.5399755 0.5399748 ## 6 50.85724 0.2477768 0.2477774  #Looking at data before analysis multiple_stocks_df %\u0026gt;% ggplot(aes(x = ref.date, y = ret.adjusted.prices)) + geom_line( aes(colour = ticker)) + ggtitle(\u0026quot;Multiple Stocks Annual Arithmetic Return\u0026quot;) + labs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;Annual Return\u0026quot;)  ## Warning: Removed 6 row(s) containing missing values (geom_path).  [Daily Return data is hard to interpret.]\nCumulative Daily Stock Return for Multiple Stocks #Cumulative Stock Return for Multiple Stocks multiple_stocks_daily \u0026lt;- BatchGetSymbols(tickers, first.date = '2007-01-01', last.date = \u0026quot;2020-06-30\u0026quot;, freq.data = \u0026quot;daily\u0026quot;, type.return = \u0026quot;arit\u0026quot;)  ## ## Running BatchGetSymbols for: ## tickers =RSP, DIA, AAPL, DIS, GOOG, BAR, UAL ## Downloading data for benchmark ticker ## ^GSPC | yahoo (1|1) | Found cache file ## RSP | yahoo (1|7) | Found cache file - Got 100% of valid prices | Feels good! ## DIA | yahoo (2|7) | Found cache file - Got 100% of valid prices | Looking good! ## AAPL | yahoo (3|7) | Found cache file - Got 100% of valid prices | Got it! ## DIS | yahoo (4|7) | Found cache file - Got 100% of valid prices | OK! ## GOOG | yahoo (5|7) | Found cache file - Got 100% of valid prices | Got it! ## BAR | yahoo (6|7) | Found cache file - Got 21% of valid prices | OUT: not enough data (thresh.bad.data = 75%) ## UAL | yahoo (7|7) | Found cache file - Got 100% of valid prices | Youre doing good!  #converting the df.tickers data package into a data frame multiple_stocks_daily_ret_df \u0026lt;- data.frame(multiple_stocks_daily$df.tickers) #Data that is missing or categorized as NA is replaced with a 0 to make analysis easier multiple_stocks_daily_ret_df[is.na(multiple_stocks_daily_ret_df)] \u0026lt;- 0 #Need to check to see if NAs are replaced with 0s head(multiple_stocks_daily_ret_df)  ## price.open price.high price.low price.close volume price.adjusted ref.date ## 1 47.58 47.79 47.04 47.32 458900 38.05593 2007-01-03 ## 2 47.27 47.48 47.04 47.39 323100 38.11223 2007-01-04 ## 3 47.23 47.23 46.94 47.07 291500 37.85487 2007-01-05 ## 4 47.01 47.23 46.89 47.17 279000 37.93529 2007-01-08 ## 5 47.25 47.30 46.97 47.23 354500 37.98356 2007-01-09 ## 6 47.10 47.42 46.97 47.37 249600 38.09615 2007-01-10 ## ticker ret.adjusted.prices ret.closing.prices ## 1 RSP 0.000000000 0.000000000 ## 2 RSP 0.001479139 0.001479269 ## 3 RSP -0.006752453 -0.006752458 ## 4 RSP 0.002124350 0.002124453 ## 5 RSP 0.001272272 0.001272037 ## 6 RSP 0.002964204 0.002964196  #Calculating the cumulative daily return using the cumprod function cumulative_multiple_stocks_daily \u0026lt;- multiple_stocks_daily_ret_df %\u0026gt;% group_by(ticker) %\u0026gt;% mutate(creturn = cumprod(1 + ret.adjusted.prices)-1) #(1 + r) * (1 + r)... #Looking at data before plotting. Want to check to see if the cumulative product function worked correctly. head(cumulative_multiple_stocks_daily)  ## # A tibble: 6 x 11 ## # Groups: ticker [1] ## price.open price.high price.low price.close volume price.adjusted ref.date ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;date\u0026gt; ## 1 47.6 47.8 47.0 47.3 458900 38.1 2007-01-03 ## 2 47.3 47.5 47.0 47.4 323100 38.1 2007-01-04 ## 3 47.2 47.2 46.9 47.1 291500 37.9 2007-01-05 ## 4 47.0 47.2 46.9 47.2 279000 37.9 2007-01-08 ## 5 47.2 47.3 47.0 47.2 354500 38.0 2007-01-09 ## 6 47.1 47.4 47.0 47.4 249600 38.1 2007-01-10 ## # … with 4 more variables: ticker \u0026lt;chr\u0026gt;, ret.adjusted.prices \u0026lt;dbl\u0026gt;, ## # ret.closing.prices \u0026lt;dbl\u0026gt;, creturn \u0026lt;dbl\u0026gt;  #See Multiple Stock Cumulative Return cumulative_multiple_stocks_daily %\u0026gt;% group_by(ticker) %\u0026gt;% # Need to group multiple stocks ggplot(aes(x = ref.date, y = creturn, color = ticker)) + geom_line() + labs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;Cumulative Returns\u0026quot;) + ggtitle(\u0026quot;Cumulative returns for Multiple Stocks Since 2007\u0026quot;) + scale_color_brewer(type = 'qual') + theme_dark()  [Apple has the highest cumulative return compared to all the other stocks in the group. $1 of Apple at the beginning of 2007 is equal to $35 today]\nCalculating the Standard Deviation for Multiple Stock #Using the standard deviation function from R to find the SD of multiple stocks. The SD is multiplied by the square root of 252 to annualized the data. 252 is the average number of trading days in a year. Multiple_Stocks_SD_Table \u0026lt;- cumulative_multiple_stocks_daily %\u0026gt;% group_by(ticker) %\u0026gt;% summarize(standard_deviation = round(StdDev(ret.adjusted.prices) * sqrt(252), digits=4) * 100) #Looking at the data before plotting head(Multiple_Stocks_SD_Table)  ## # A tibble: 6 x 2 ## ticker standard_deviation[,1] ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 AAPL 32.2 ## 2 DIA 20.2 ## 3 DIS 28.0 ## 4 GOOG 29.4 ## 5 RSP 22.7 ## 6 UAL 69.6  #Using Bar Graph to plot Mean Annual Return for Multiple Stock in Descending Order ggplot(data = Multiple_Stocks_SD_Table, aes(x = reorder(ticker, -standard_deviation), y= standard_deviation)) + geom_bar(stat=\u0026quot;identity\u0026quot;, fill= \u0026quot;blue\u0026quot;, colour=\u0026quot;orange\u0026quot;) + geom_text(aes(label = paste(standard_deviation, \u0026quot;%\u0026quot;, sep = \u0026quot;\u0026quot;)), nudge_y = 2) + ggtitle(\u0026quot;Multiple Stocks Mean Annual Arithmetic Returns Since 2007\u0026quot;) + labs(x = \u0026quot;Company\u0026quot;, y = \u0026quot;Mean Annual Return\u0026quot;)  [Stocks are arranged in order of descending riskiness. United Airlines has the highest level of risk with an SD of 69.6%, followed by Apple, Google, etc. Not suprising the RSP and DIA ETFs have the lowest risk out of this group of stocks given they represent the overall market]\n","date":1594771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594859603,"objectID":"18eb6f0cf33f721bac1d7f8dae2cdc68","permalink":"/post/stock-return-and-risk-calculations/","publishdate":"2020-07-15T00:00:00Z","relpermalink":"/post/stock-return-and-risk-calculations/","section":"post","summary":"This post will center on simple stock portfolio risk and return analysis using R Install all necessary packages. #install.packages(\u0026quot;tidyquant\u0026quot;) #install.packages(\u0026quot;timetk\u0026quot;) #install.packages(\u0026quot;plyr\u0026quot;) #install.packages(\u0026quot;knitr\u0026quot;) #install.packages(\u0026quot;dplyr\u0026quot;) #install.packages(\u0026quot;quantmod\u0026quot;) #install.packages(\u0026quot;BatchGetSymbols\u0026quot;) #install.packages(\u0026quot;tsbox\u0026quot;) #install.packages(\u0026quot;lubridate\u0026quot;) library(\u0026quot;tidyquant\u0026quot;) library(\u0026quot;timetk\u0026quot;) library(\u0026quot;ggplot2\u0026quot;) library(\u0026quot;plyr\u0026quot;) library(\u0026quot;knitr\u0026quot;) library(\u0026quot;dplyr\u0026quot;) library(\u0026quot;quantmod\u0026quot;) library(\u0026quot;BatchGetSymbols\u0026quot;) library(\u0026quot;tsbox\u0026quot;) library(\u0026quot;lubridate\u0026quot;)  Downloading and Plotting Daily Return Data #Data is downloaded using get_symbols function from quantmod RSP \u0026lt;- getSymbols(\u0026quot;RSP\u0026quot;, src = \u0026quot;yahoo\u0026quot;, from = '2003-04-30', to = \u0026quot;2020-07-07\u0026quot;, auto.","tags":[],"title":"Stock Return and Risk Calculations","type":"post"},{"authors":[],"categories":[],"content":" Data Types A data type is an attribute of data that gives a programmer an indicator of how the data will be used. In R there are a wide assortment of data types that include scalars(character, numeric, logical, integer, complex), vectors, matrices, and data frames. It is important to know the data type of each variable in a dataset before analyses can be done. Data types can make calculations faster and more efficient depending on the analyses.\nScalars Scalars are data types that hold only one type at a time, whether it be a character, numeric, logical, integer, or complex. We are going to download a multitude of datasets through the ‘datasets’ package in R to look at some examples of data types.\nCharacter variable data types are usually alphabetic but always require \u0026quot;\u0026quot; when used in a dataset. Ex: “Apple”, “Porsche”, “Tom”… etc.\nNumeric is self exaplanatory. This datatype is the most common data type that I encounter and include anything, well numeric. Ex: 9494, 950300, 00008… etc. The two most common types of numeric data types are integer and double.\n1)Integer is a numeric data type that stores whole numbers, anything from negative to positive values. For SQL servers,integers range from -2,147,483,647 to 2,147,483,647.\n2)Double is a numeric data type that stores numbers with up to 17 decimals. Ex. 59903.99595959\nLogical is a special data type with only two possible values. Ex: 0/1, true/false, yes/no, etc. I typically use logical data types as a flag variable if I want to identify if a condition exists or not.\nComplex data type is anything that is not included in the previous data types. Example is 1 - 2i, see example below\n# numeric is probably the most common data type you will encounter in data science # downloading \u0026#39;datasets\u0026#39; package library(datasets) # viewing all datasets in the package data() # picking \u0026#39;mtcars\u0026#39; dataset to view. Head function gives us a quick glance at all of the columns head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 # \u0026#39;str\u0026#39; function like the head function lets us view all variables in the dataset but lists the data types in the dataset as well str(mtcars) ## \u0026#39;data.frame\u0026#39;: 32 obs. of 11 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... ## $ disp: num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec: num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear: num 4 4 4 3 3 3 3 4 4 4 ... ## $ carb: num 4 4 1 1 2 1 4 2 2 4 ... #Here we can see the UC Berkley Admissions dataset that contains character variables str(UCBAdmissions) ## \u0026#39;table\u0026#39; num [1:2, 1:2, 1:6] 512 313 89 19 353 207 17 8 120 205 ... ## - attr(*, \u0026quot;dimnames\u0026quot;)=List of 3 ## ..$ Admit : chr [1:2] \u0026quot;Admitted\u0026quot; \u0026quot;Rejected\u0026quot; ## ..$ Gender: chr [1:2] \u0026quot;Male\u0026quot; \u0026quot;Female\u0026quot; ## ..$ Dept : chr [1:6] \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot; \u0026quot;D\u0026quot; ... #Example of complex data type. The \u0026#39;class\u0026#39; function is used to determine the data type. z = 1 + 2i z ## [1] 1+2i class(z) ## [1] \u0026quot;complex\u0026quot;  Vectors A vector is a basic data structure that always contain elements of the same type\n# the \u0026#39;\u0026lt;-\u0026#39; is used to store values in a variable, and \u0026#39;c()\u0026#39; is the combine function x \u0026lt;- c(9, 4, 5, 6, 7, 10) #all values in this data structure are double typeof(x) ## [1] \u0026quot;double\u0026quot; #Because vectors contain elements of the same type, this function will try to convert all values in the vector to one data type. This conversion occurs from lower to higher types, from logical to integer to double to character, with character data type being the most influential x \u0026lt;- c(1, 5.4, TRUE, \u0026quot;hello\u0026quot;) x ## [1] \u0026quot;1\u0026quot; \u0026quot;5.4\u0026quot; \u0026quot;TRUE\u0026quot; \u0026quot;hello\u0026quot; # Here we can see that all values were converted to a character data type class(x) ## [1] \u0026quot;character\u0026quot; #There are many caveats to vectors but for the sake of staying on topic, we will discuss in another post  Matrices Matrices are data structures that are two dimensional, and like vectors will contain values of all the same data type.\nPersonally I do not use matrices all that much, except maybe correlation tables related to stock analyses, but otherwise they are important to know about.\n#You can create a matrix using the \u0026#39;matrix\u0026#39; function matrix(data, nrow, ncol, byrow, dimnames) M \u0026lt;- matrix(c(1:45), nrow=5, byrow = TRUE) #new function \u0026#39;print\u0026#39; shows the input value or matrix print(M) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] ## [1,] 1 2 3 4 5 6 7 8 9 ## [2,] 10 11 12 13 14 15 16 17 18 ## [3,] 19 20 21 22 23 24 25 26 27 ## [4,] 28 29 30 31 32 33 34 35 36 ## [5,] 37 38 39 40 41 42 43 44 45  Data Frames Data Frames are the data type that most people are familiar with. Like matrices, data frames are two dimensional structures but contain variables that can be composed of different data types such as numeric, character or logical. Data frames have rows and columns, usually with rows of unique observations\ndata() #Looking at Freeny\u0026#39;s Revenue Data. head(freeny) ## y lag.quarterly.revenue price.index income.level market.potential ## 1962.25 8.79236 8.79636 4.70997 5.82110 12.9699 ## 1962.5 8.79137 8.79236 4.70217 5.82558 12.9733 ## 1962.75 8.81486 8.79137 4.68944 5.83112 12.9774 ## 1963 8.81301 8.81486 4.68558 5.84046 12.9806 ## 1963.25 8.90751 8.81301 4.64019 5.85036 12.9831 ## 1963.5 8.93673 8.90751 4.62553 5.86464 12.9854 class(freeny) ## [1] \u0026quot;data.frame\u0026quot; Hope this information is helpful.\n  ","date":1593734400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593802419,"objectID":"343cdc1f8c115d8a0b1eb9e9646fd07f","permalink":"/post/data-types/","publishdate":"2020-07-03T00:00:00Z","relpermalink":"/post/data-types/","section":"post","summary":"Data Types A data type is an attribute of data that gives a programmer an indicator of how the data will be used. In R there are a wide assortment of data types that include scalars(character, numeric, logical, integer, complex), vectors, matrices, and data frames.","tags":[],"title":"Data Types","type":"post"},{"authors":[],"categories":[],"content":"R Basics What is R? How can I use R? R is an open-source statistical program that can handle anything from basic addition and subtraction to advanced modeling. It is an amazing resource for anyone in data science, finance, health statistics, etc. This blog is designed for those who are beginners wanting to learn more about R and its vast array of tools. This blog will become progressively more advanced but it is important to start from a solid base.\nAddition Updated the variables to calculate eight hundred and fourty seven plus three thousand four hundred and eighty nine.\n# Addition 847 + 3489  ## [1] 4336  Subtraction Update the variables to calculate one thousand three hundred and seven minus eight seven.\n# Subtraction 1307 - 87  ## [1] 1220  Multiplication Let\u0026rsquo;s calculate twelve times ninety\n# Multiplication 12 * 90  ## [1] 1080  Division \\(\\div\\) Determine one quarter of five thousand and four.\n# Division 5004/4  ## [1] 1251  Session Info devtools::session_info()  ## ─ Session info ─────────────────────────────────────────────────────────────── ## setting value ## version R version 3.5.1 (2018-07-02) ## os macOS 10.15.4 ## system x86_64, darwin15.6.0 ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz America/New_York ## date 2020-06-28 ## ## ─ Packages ─────────────────────────────────────────────────────────────────── ## package * version date lib source ## assertthat 0.2.0 2017-04-11 [2] CRAN (R 3.5.0) ## backports 1.1.2 2017-12-13 [2] CRAN (R 3.5.0) ## blogdown 0.19 2020-05-22 [1] CRAN (R 3.5.1) ## bookdown 0.19 2020-05-15 [1] CRAN (R 3.5.1) ## callr 3.4.3 2020-03-28 [1] CRAN (R 3.5.1) ## cli 2.0.2 2020-02-28 [1] CRAN (R 3.5.2) ## crayon 1.3.4 2017-09-16 [2] CRAN (R 3.5.0) ## desc 1.2.0 2018-05-01 [1] CRAN (R 3.5.0) ## devtools 2.3.0 2020-04-10 [1] CRAN (R 3.5.1) ## digest 0.6.25 2020-02-23 [1] CRAN (R 3.5.2) ## ellipsis 0.3.1 2020-05-15 [1] CRAN (R 3.5.1) ## evaluate 0.14 2019-05-28 [1] CRAN (R 3.5.2) ## fansi 0.4.1 2020-01-08 [1] CRAN (R 3.5.2) ## fs 1.4.1 2020-04-04 [1] CRAN (R 3.5.1) ## glue 1.4.1 2020-05-13 [1] CRAN (R 3.5.1) ## htmltools 0.5.0 2020-06-16 [1] CRAN (R 3.5.1) ## knitr 1.29 2020-06-23 [1] CRAN (R 3.5.1) ## magrittr 1.5 2014-11-22 [2] CRAN (R 3.5.0) ## memoise 1.1.0 2017-04-21 [1] CRAN (R 3.5.0) ## pkgbuild 1.0.8 2020-05-07 [1] CRAN (R 3.5.1) ## pkgload 1.1.0 2020-05-29 [1] CRAN (R 3.5.1) ## prettyunits 1.1.1 2020-01-24 [1] CRAN (R 3.5.2) ## processx 3.4.2 2020-02-09 [1] CRAN (R 3.5.2) ## ps 1.3.3 2020-05-08 [1] CRAN (R 3.5.1) ## R6 2.2.2 2017-06-17 [2] CRAN (R 3.5.0) ## remotes 2.1.1 2020-02-15 [1] CRAN (R 3.5.2) ## rlang 0.4.6 2020-05-02 [1] CRAN (R 3.5.1) ## rmarkdown 2.3 2020-06-18 [1] CRAN (R 3.5.1) ## rprojroot 1.3-2 2018-01-03 [2] CRAN (R 3.5.0) ## sessioninfo 1.1.1 2018-11-05 [1] CRAN (R 3.5.0) ## stringi 1.2.4 2018-07-20 [2] CRAN (R 3.5.0) ## stringr 1.4.0 2019-02-10 [1] CRAN (R 3.5.2) ## testthat 2.3.2 2020-03-02 [1] CRAN (R 3.5.2) ## usethis 1.6.1 2020-04-29 [1] CRAN (R 3.5.1) ## withr 2.1.2 2018-03-15 [2] CRAN (R 3.5.0) ## xfun 0.15 2020-06-21 [1] CRAN (R 3.5.1) ## yaml 2.2.0 2018-07-25 [2] CRAN (R 3.5.0) ## ## [1] /Users/colinbenusa/Library/R/3.5/library ## [2] /Library/Frameworks/R.framework/Versions/3.5/Resources/library  date()  ## [1] \u0026quot;Sun Jun 28 13:52:33 2020\u0026quot;  sessionInfo()  ## R version 3.5.1 (2018-07-02) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS 10.15.4 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] knitr_1.29 magrittr_1.5 usethis_1.6.1 devtools_2.3.0 ## [5] pkgload_1.1.0 R6_2.2.2 rlang_0.4.6 fansi_0.4.1 ## [9] stringr_1.4.0 tools_3.5.1 pkgbuild_1.0.8 xfun_0.15 ## [13] sessioninfo_1.1.1 cli_2.0.2 withr_2.1.2 remotes_2.1.1 ## [17] htmltools_0.5.0 ellipsis_0.3.1 rprojroot_1.3-2 yaml_2.2.0 ## [21] assertthat_0.2.0 digest_0.6.25 crayon_1.3.4 bookdown_0.19 ## [25] processx_3.4.2 callr_3.4.3 fs_1.4.1 ps_1.3.3 ## [29] testthat_2.3.2 memoise_1.1.0 glue_1.4.1 evaluate_0.14 ## [33] rmarkdown_2.3 blogdown_0.19 stringi_1.2.4 compiler_3.5.1 ## [37] backports_1.1.2 desc_1.2.0 prettyunits_1.1.1  date()  ## [1] \u0026quot;Sun Jun 28 13:52:33 2020\u0026quot;  Sys.getenv()  ## __CF_USER_TEXT_ENCODING ## 0x1F5:0x0:0x0 ## CENSUS_API_KEY becc687c781c8c5d1e7dda0c2c046b0c507d217a ## CLICOLOR_FORCE 1 ## DISPLAY /private/tmp/com.apple.launchd.0WSV3uhIlW/org.macosforge.xquartz:0 ## DYLD_FALLBACK_LIBRARY_PATH ## /Library/Frameworks/R.framework/Resources/lib:/Library/Java/JavaVirtualMachines/jdk-9.jdk/Contents/Home/lib/server ## EDITOR vi ## GIT_ASKPASS rpostback-askpass ## GITHUB_PAT bcf752b629b80d38e13a52edb60c5353249a4191] ## HOME /Users/colinbenusa ## LANG en_US.UTF-8 ## LC_CTYPE en_US.UTF-8 ## LN_S ln -s ## LOGNAME colinbenusa ## MAKE make ## MPLENGINE tkAgg ## PAGER /usr/bin/less ## PATH /usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/Library/TeX/texbin:/opt/X11/bin:/Library/Apple/usr/bin ## PWD /Users/colinbenusa/Blog with R ## R_ARCH ## R_BROWSER /usr/bin/open ## R_BZIPCMD /usr/bin/bzip2 ## R_DOC_DIR /Library/Frameworks/R.framework/Resources/doc ## R_GZIPCMD /usr/bin/gzip ## R_HOME /Library/Frameworks/R.framework/Resources ## R_INCLUDE_DIR /Library/Frameworks/R.framework/Resources/include ## R_LIBS_SITE ## R_LIBS_USER ~/Library/R/3.5/library ## R_PAPERSIZE a4 ## R_PAPERSIZE_USER a4 ## R_PDFVIEWER /usr/bin/open ## R_PLATFORM x86_64-apple-darwin15.6.0 ## R_PRINTCMD lpr ## R_QPDF /Library/Frameworks/R.framework/Resources/bin/qpdf ## R_RD4PDF times,inconsolata,hyper ## R_SESSION_TMPDIR /var/folders/m8/4ph0yk_12zddg0z7btxz7tp80000gn/T//RtmpBEL1P3 ## R_SHARE_DIR /Library/Frameworks/R.framework/Resources/share ## R_SYSTEM_ABI osx,gcc,gxx,gfortran,? ## R_TEXI2DVICMD /usr/local/bin/texi2dvi ## R_UNZIPCMD /usr/bin/unzip ## R_ZIPCMD /usr/bin/zip ## RMARKDOWN_MATHJAX_PATH ## /Applications/RStudio.app/Contents/Resources/resources/mathjax-26 ## RS_PPM_FD_READ 25 ## RS_PPM_FD_WRITE 54 ## RS_RPOSTBACK_PATH /Applications/RStudio.app/Contents/MacOS/rpostback ## RS_SHARED_SECRET 2824752491622650073984943658 ## RSTUDIO 1 ## RSTUDIO_CONSOLE_COLOR 256 ## RSTUDIO_CONSOLE_WIDTH 95 ## RSTUDIO_PANDOC /Applications/RStudio.app/Contents/MacOS/pandoc ## RSTUDIO_SESSION_PORT 34856 ## RSTUDIO_USER_IDENTITY colinbenusa ## RSTUDIO_WINUTILS bin/winutils ## SED /usr/bin/sed ## SHELL /bin/bash ## SHLVL 1 ## SSH_ASKPASS rpostback-askpass ## SSH_AUTH_SOCK /private/tmp/com.apple.launchd.oNyQnin255/Listeners ## TAR /usr/bin/tar ## TERM xterm-256color ## TMPDIR /var/folders/m8/4ph0yk_12zddg0z7btxz7tp80000gn/T/ ## USER colinbenusa ## XPC_FLAGS 0x0 ## XPC_SERVICE_NAME org.rstudio.RStudio.1432  ","date":1592956800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593026938,"objectID":"a4677231881107c9d2d9d89e0c3e8d8d","permalink":"/post/r-for-beginners/r-for-beginners/","publishdate":"2020-06-24T00:00:00Z","relpermalink":"/post/r-for-beginners/r-for-beginners/","section":"post","summary":"R Basics What is R? How can I use R? R is an open-source statistical program that can handle anything from basic addition and subtraction to advanced modeling. It is an amazing resource for anyone in data science, finance, health statistics, etc.","tags":[],"title":"R for Beginners","type":"post"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() ```  renders as\nimport pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head()  Math Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$  renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\\\\\ math linebreak:\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\\\\ 1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$  renders as\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ```  renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2]  An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ```  renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good!  An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ```  renders as\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d  An example class diagram:\n```mermaid classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } ```  renders as\nclassDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() }  An example state diagram:\n```mermaid stateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] ```  renders as\nstateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*]  Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else  renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell |  renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Asides Academic supports a shortcode for asides, also referred to as notices, hints, or alerts. By wrapping a paragraph in {{% alert note %}} ... {{% /alert %}}, it will render as an aside.\n{{% alert note %}} A Markdown aside is useful for displaying notices, hints, or definitions to your readers. {{% /alert %}}  renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Spoilers Add a spoiler to a page to reveal text, such as an answer to a question, after a button is clicked.\n{{\u0026lt; spoiler text=\u0026quot;Click to view the spoiler\u0026quot; \u0026gt;}} You found me! {{\u0026lt; /spoiler \u0026gt;}}  renders as\n Click to view the spoiler  You found me!    Icons Academic enables you to use a wide range of icons from Font Awesome and Academicons in addition to emojis.\nHere are some examples using the icon shortcode to render icons:\n{{\u0026lt; icon name=\u0026quot;terminal\u0026quot; pack=\u0026quot;fas\u0026quot; \u0026gt;}} Terminal {{\u0026lt; icon name=\u0026quot;python\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} Python {{\u0026lt; icon name=\u0026quot;r-project\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} R  renders as\n  Terminal\n Python\n R\nDid you find this page helpful? Consider sharing it 🙌 ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":["Colin Benusa"],"categories":null,"content":" Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":["Colin Benusa"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and JupyterLab  Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb  The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata ( front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... ---  Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.  Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Colin Benusa","吳恩達"],"categories":["Demo","教程"],"content":"Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\n Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n 👉 Get Started 📚 View the documentation 💬 Ask a question on the forum 👥 Chat with the community 🐦 Twitter: @source_themes @GeorgeCushen #MadeWithAcademic 💡 Request a feature or report a bug ⬆️ Updating? View the Update Guide and Release Notes ❤️ Support development of Academic:  ☕️ Donate a coffee 💵 Become a backer on Patreon 🖼️ Decorate your laptop or journal with an Academic sticker 👕 Wear the T-shirt 👩‍💻 Contribute      Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.   Key features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Academic comes with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the sun/moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\n Choose a stunning theme and font for your site. Themes are fully customizable.\nEcosystem   Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site  Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n  one-click install using your web browser (recommended)  install on your computer using Git with the Command Prompt/Terminal app  install on your computer by downloading the ZIP files  install on your computer with RStudio  Then personalize and deploy your new site.\nUpdating  View the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"/post/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website in under 10 minutes.","tags":["Academic","开源"],"title":"Academic: the website builder for Hugo","type":"post"},{"authors":["Colin Benusa","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Colin Benusa","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"}]